{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 10:03:25.017744: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-28 10:03:25.091262: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-28 10:03:25.464433: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-28 10:03:25.464473: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-28 10:03:25.464477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import enum\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from spear.labeling import PreLabels\n",
    "import numpy as np\n",
    "from spear.cage import Cage\n",
    "from utils import custom_dataset, train_all_LF, get_various_data\n",
    "from generate_LF import get_variables\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelling_function import *\n",
    "from PIL import Image\n",
    "from resnet18 import ResNet, BasicBlock\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from resnet18 import ResNet, BasicBlock\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = None\n",
    "\n",
    "class ClassLabels(enum.Enum):\n",
    "    LYMPHOCYTE= 0\n",
    "    NONLYMPHOCYTE = 1\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n",
    "# path = \"/home/akshit/Desktop/MICCAI/data/models/\"\n",
    "path = \"/home/raja/Desktop/MICCAI/data/models/100/\"\n",
    "\n",
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    #x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'0_svmV11.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][0]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_V1, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_svm0_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    #x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'0_svmV11.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][0]>0.50: \n",
    "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm1_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    #x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'1_svmV11.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm1_V1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_svm1_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    #x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'1_svmV11.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][1]>0.6: \n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelling_function import *\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL1(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if blue_score > 155:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL2(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    if 10 < blue_score < 180 and red_score > 170:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN    \n",
    "    \n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL9(c,**kwargs): \n",
    "    green_score = calculate_green_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    if 10 < blue_score < 180 and green_score > 155:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN      \n",
    "    \n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL3(c,**kwargs): \n",
    "    brown_score = compute_brown_score(c)\n",
    "    total_blue_score = compute_blue_score(c)\n",
    "    if total_blue_score < 12:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN   \n",
    "\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL4(c,**kwargs): \n",
    "    brown_score = compute_brown_score(c)\n",
    "    total_blue_score = compute_blue_score(c)\n",
    "    if brown_score > 585:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN   \n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL5(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if red_score > 170:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL6(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if red_score < 12:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL7(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if green_score > 155:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL8(c,**kwargs): \n",
    "    black_score = compute_black_score(c)\n",
    "    if black_score > 9:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN           \n",
    "\n",
    "    \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import LFSet\n",
    "\n",
    "LFS = [\n",
    "    #ResNet18LF_LYMPHOCYTE,\n",
    "    #ResNet18LF_NONLYMPHOCYTE,\n",
    "    LFNL1,\n",
    "    LFNL2,\n",
    "    LFNL3,\n",
    "    LFNL4,\n",
    "    LFNL5,\n",
    "    LFNL6,\n",
    "    LFNL7,\n",
    "    LFNL8,\n",
    "    LFNL9,\n",
    "    \n",
    "    LF_svm0_V1,\n",
    "    LF_svm1_V1,  \n",
    "  \n",
    "]\n",
    "\n",
    "QT2 = 0.99\n",
    "QC2 = 0.99\n",
    "\n",
    "qt1 = np.array([0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999])\n",
    "qc1 = np.array([0.99999,0.99999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999])\n",
    "\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import custom_dataset, train_all_LF, get_various_data\n",
    "from generate_LF import get_variables\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "dataset,X,Y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 2700)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "X, X_feats, Y = X, X, Y\n",
    "\n",
    "#X = X.reshape((210,30, 30, 3))\n",
    "\n",
    "validation_size = 2\n",
    "test_size = 2\n",
    "L_size = 202\n",
    "U_size = 4\n",
    "n_lfs = len(rules.get_lfs())\n",
    "\n",
    "X_V, Y_V, X_feats_V,_, X_T, Y_T, X_feats_T,_, X_L, Y_L, X_feats_L,_, X_U, X_feats_U,_ = get_various_data(X, Y, X_feats, n_lfs, validation_size, test_size, L_size, U_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_json = './jl_pkl/sms_json.json'\n",
    "V_path_pkl = './jl_pkl/sms_pickle_V.pkl' #validation data - have true labels\n",
    "T_path_pkl = './jl_pkl/sms_pickle_T.pkl' #test data - have true labels\n",
    "L_path_pkl = './jl_pkl/sms_pickle_L.pkl' #Labeled data - have true labels\n",
    "U_path_pkl = './jl_pkl/sms_pickle_U.pkl' #unlabelled data - don't have true labels\n",
    "\n",
    "log_path_jl_1 = './jl_pkl/sms_log_1.txt' #jl is an algorithm, can be found below\n",
    "params_path = './jl_pkl/sms_params.pkl' #file path to store parameters of JL, used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 398.57it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 457.22it/s]\n",
      "100%|██████████| 202/202 [00:00<00:00, 662.18it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 604.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from spear.labeling import PreLabels\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "train_all_LF(X,Y,len(classes),save_path,label_frac)\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"lysto\",\n",
    "                               data=X_V,\n",
    "                               gold_labels=Y_V,\n",
    "                               data_feats=X_feats_V,\n",
    "                               rules=rules,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=2)\n",
    "sms_noisy_labels.generate_pickle(V_path_pkl)\n",
    "sms_noisy_labels.generate_json(path_json) #generating json files once is enough\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"lysto\",\n",
    "                               data=X_T,\n",
    "                               gold_labels=Y_T,\n",
    "                               data_feats=X_feats_T,\n",
    "                               rules=rules,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=2)\n",
    "sms_noisy_labels.generate_pickle(T_path_pkl)\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"lysto\",\n",
    "                               data=X_L,\n",
    "                               gold_labels=Y_L,\n",
    "                               data_feats=X_feats_L,\n",
    "                               rules=rules,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=2)\n",
    "sms_noisy_labels.generate_pickle(L_path_pkl)\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"lysto\",\n",
    "                               data=X_U,\n",
    "                               rules=rules,\n",
    "                               data_feats=X_feats_U,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=2) #note that we don't pass gold_labels here, for the unlabelled data\n",
    "sms_noisy_labels.generate_pickle(U_path_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: (4, 2700)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the labeled data from the pickle file\n",
    "with open(U_path_pkl, 'rb') as f:\n",
    "    labeled_data = pickle.load(f)\n",
    "\n",
    "# Get the feature matrix from the labeled data\n",
    "U_L = labeled_data\n",
    "\n",
    "# Determine the number of features\n",
    "n_features = U_L.shape\n",
    "\n",
    "print(\"Number of features:\", n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in data list:  10\n",
      "Shape of feature matrix:  (4, 2700)\n",
      "Shape of labels matrix:  (4, 11)\n",
      "Shape of continuous scores matrix :  (4, 11)\n",
      "Total number of classes:  2\n",
      "Classes dictionary in json file(modified to have integer keys):  {0: 'LYMPHOCYTE', 1: 'NONLYMPHOCYTE'}\n"
     ]
    }
   ],
   "source": [
    "from spear.utils import get_data, get_classes\n",
    "\n",
    "data_U = get_data(path = U_path_pkl, check_shapes=True)\n",
    "#check_shapes being True(above), asserts for relative shapes of arrays in pickle file\n",
    "print(\"Number of elements in data list: \", len(data_U))\n",
    "print(\"Shape of feature matrix: \", data_U[0].shape)\n",
    "print(\"Shape of labels matrix: \", data_U[1].shape)\n",
    "print(\"Shape of continuous scores matrix : \", data_U[6].shape)\n",
    "print(\"Total number of classes: \", data_U[9])\n",
    "\n",
    "classes = get_classes(path = path_json)\n",
    "print(\"Classes dictionary in json file(modified to have integer keys): \", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in data list:  10\n",
      "Shape of feature matrix:  (202, 2700)\n",
      "Shape of labels matrix:  (202, 11)\n",
      "Shape of continuous scores matrix :  (202, 11)\n",
      "Total number of classes:  2\n",
      "Classes dictionary in json file(modified to have integer keys):  {0: 'LYMPHOCYTE', 1: 'NONLYMPHOCYTE'}\n"
     ]
    }
   ],
   "source": [
    "from spear.utils import get_data, get_classes\n",
    "\n",
    "data_U = get_data(path = L_path_pkl, check_shapes=True)\n",
    "#check_shapes being True(above), asserts for relative shapes of arrays in pickle file\n",
    "print(\"Number of elements in data list: \", len(data_U))\n",
    "print(\"Shape of feature matrix: \", data_U[0].shape)\n",
    "print(\"Shape of labels matrix: \", data_U[1].shape)\n",
    "print(\"Shape of continuous scores matrix : \", data_U[6].shape)\n",
    "print(\"Total number of classes: \", data_U[9])\n",
    "\n",
    "classes = get_classes(path = path_json)\n",
    "print(\"Classes dictionary in json file(modified to have integer keys): \", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from spear.jl import JL\n",
    "\n",
    "n_features = 2700\n",
    "n_hidden = 512\n",
    "feature_model = 'nn'\n",
    "'''\n",
    "'nn' is neural network. other alternative is 'lr'(logistic regression) which doesn't need n_hidden to be passed\n",
    "during initialisation.\n",
    "''' \n",
    "\n",
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, feature_model = feature_model, \\\n",
    "        n_hidden = n_hidden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m use_accuracy_score \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m jl \u001b[39m=\u001b[39m JL(path_json \u001b[39m=\u001b[39m path_json, n_lfs \u001b[39m=\u001b[39m n_lfs, n_features \u001b[39m=\u001b[39m n_features, feature_model \u001b[39m=\u001b[39m feature_model, n_hidden \u001b[39m=\u001b[39m n_hidden)\n\u001b[0;32m---> 18\u001b[0m probs_fm, probs_gm \u001b[39m=\u001b[39m jl\u001b[39m.\u001b[39;49mfit_and_predict_proba(path_L \u001b[39m=\u001b[39;49m L_path_pkl, path_U \u001b[39m=\u001b[39;49m U_path_pkl, path_V \u001b[39m=\u001b[39;49m V_path_pkl, path_T \u001b[39m=\u001b[39;49m T_path_pkl, loss_func_mask \u001b[39m=\u001b[39;49m loss_func_mask, batch_size \u001b[39m=\u001b[39;49m batch_size, lr_fm \u001b[39m=\u001b[39;49m lr_fm, lr_gm \u001b[39m=\u001b[39;49m lr_gm, use_accuracy_score \u001b[39m=\u001b[39;49m use_accuracy_score, path_log \u001b[39m=\u001b[39;49m log_path_jl_1, return_gm \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, n_epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, start_len \u001b[39m=\u001b[39;49m \u001b[39m7\u001b[39;49m,stop_len \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m, is_qt \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, is_qc \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, qt \u001b[39m=\u001b[39;49m \u001b[39m0.9\u001b[39;49m, qc \u001b[39m=\u001b[39;49m \u001b[39m0.85\u001b[39;49m, metric_avg \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mbinary\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     20\u001b[0m labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(probs_fm, \u001b[39m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mprobs_fm shape: \u001b[39m\u001b[39m\"\u001b[39m, probs_fm\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Desktop/cage/lib/python3.10/site-packages/spear/jl/core.py:367\u001b[0m, in \u001b[0;36mJL.fit_and_predict_proba\u001b[0;34m(self, path_L, path_U, path_V, path_T, loss_func_mask, batch_size, lr_fm, lr_gm, use_accuracy_score, path_log, return_gm, n_epochs, start_len, stop_len, is_qt, is_qc, qt, qc, metric_avg)\u001b[0m\n\u001b[1;32m    364\u001b[0m \tloss_1 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    366\u001b[0m \u001b[39mif\u001b[39;00m(loss_func_mask[\u001b[39m1\u001b[39m]):\n\u001b[0;32m--> 367\u001b[0m \tunsupervised_fm_probability \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mSoftmax(dim \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_model(sample[\u001b[39m0\u001b[39;49m][unsupervised_indices]))\n\u001b[1;32m    368\u001b[0m \tloss_2 \u001b[39m=\u001b[39m entropy(unsupervised_fm_probability)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/cage/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/cage/lib/python3.10/site-packages/torch/nn/modules/activation.py:1482\u001b[0m, in \u001b[0;36mSoftmax.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49msoftmax(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdim, _stacklevel\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/cage/lib/python3.10/site-packages/torch/nn/functional.py:1843\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1842\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1843\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[1;32m   1844\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1845\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "loss_func_mask = [1,1,0,1,0,0,1] \n",
    "#loss_func_mask = [0,0,0,0,0,0,1]\n",
    "'''\n",
    "One can keep 0s in places where he don't want the specific loss function to be part\n",
    "the final loss function used in training. Refer documentation(spear.JL.core.JL) to understand\n",
    "the which index of loss_func_mask refers to what loss function.\n",
    "\n",
    "Note: the loss_func_mask above may not be the optimal mask for sms dataset. We have to try\n",
    "      some other masks too, to find the best one that gives good accuracies.\n",
    "'''\n",
    "batch_size = 50\n",
    "lr_fm = 0.0005\n",
    "lr_gm = 0.01\n",
    "use_accuracy_score = False\n",
    "\n",
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, feature_model = feature_model, n_hidden = n_hidden)\n",
    "\n",
    "probs_fm, probs_gm = jl.fit_and_predict_proba(path_L = L_path_pkl, path_U = U_path_pkl, path_V = V_path_pkl, path_T = T_path_pkl, loss_func_mask = loss_func_mask, batch_size = batch_size, lr_fm = lr_fm, lr_gm = lr_gm, use_accuracy_score = use_accuracy_score, path_log = log_path_jl_1, return_gm = True, n_epochs = 100, start_len = 7,stop_len = 10, is_qt = True, is_qc = True, qt = 0.9, qc = 0.85, metric_avg = 'binary')\n",
    "\n",
    "labels = np.argmax(probs_fm, 1)\n",
    "print(\"probs_fm shape: \", probs_fm.shape)\n",
    "print(\"probs_gm shape: \", probs_gm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:00<00:10,  9.36it/s]/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 19%|█▉        | 19/100 [00:02<00:08,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping at epoch: 19\tbest_epoch: 8\n",
      "score used: f1_score\n",
      "best_gm_val_score:1.0\tbest_fm_val_score:0.6666666666666666\n",
      "best_gm_test_score:1.0\tbest_fm_test_score:1.0\n",
      "best_gm_test_precision:1.0\tbest_fm_test_precision:1.0\n",
      "best_gm_test_recall:1.0\tbest_fm_test_recall:1.0\n",
      "labels_fm shape:  (4,)\n",
      "labels_gm shape:  (4,)\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "feature_model = 'nn' #resetting feature_model as 'nn'(neural network) for further trainings\n",
    "\n",
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, feature_model = feature_model, \\\n",
    "        n_hidden = n_hidden)\n",
    "\n",
    "labels_fm, labels_gm = jl.fit_and_predict(path_L = L_path_pkl, path_U = U_path_pkl, path_V = V_path_pkl, \\\n",
    "        path_T = T_path_pkl, loss_func_mask = loss_func_mask, batch_size = batch_size, lr_fm = lr_fm, lr_gm = \\\n",
    "    lr_gm, use_accuracy_score = use_accuracy_score, path_log = log_path_jl_1, return_gm = True, n_epochs = \\\n",
    "    100, start_len = 7,stop_len = 10, is_qt = True, is_qc = True, qt = 0.9, qc = 0.85, metric_avg = 'binary', \\\n",
    "    need_strings = False)\n",
    "\n",
    "print(\"labels_fm shape: \", labels_fm.shape)\n",
    "print(\"labels_gm shape: \", labels_gm.shape)\n",
    "print(type(labels_fm[0]))\n",
    "print(type(labels_gm[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  2%|▏         | 2/100 [00:00<00:09,  9.89it/s]/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  4%|▍         | 4/100 [00:00<00:09,  9.83it/s]/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  6%|▌         | 6/100 [00:00<00:09,  9.59it/s]/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 16%|█▌        | 16/100 [00:01<00:09,  9.29it/s]/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 19%|█▉        | 19/100 [00:02<00:08,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping at epoch: 19\tbest_epoch: 8\n",
      "score used: f1_score\n",
      "best_gm_val_score:1.0\tbest_fm_val_score:0.0\n",
      "best_gm_test_score:1.0\tbest_fm_test_score:1.0\n",
      "best_gm_test_precision:1.0\tbest_fm_test_precision:1.0\n",
      "best_gm_test_recall:1.0\tbest_fm_test_recall:1.0\n",
      "labels_fm shape:  (4,)\n",
      "labels_gm shape:  (4,)\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, feature_model = feature_model, \\\n",
    "        n_hidden = n_hidden)\n",
    "\n",
    "labels_fm, labels_gm = jl.fit_and_predict(path_L = L_path_pkl, path_U = U_path_pkl, path_V = V_path_pkl, \\\n",
    "        path_T = T_path_pkl, loss_func_mask = loss_func_mask, batch_size = batch_size, lr_fm = lr_fm, lr_gm = \\\n",
    "    lr_gm, use_accuracy_score = use_accuracy_score, path_log = log_path_jl_1, return_gm = True, n_epochs = \\\n",
    "    100, start_len = 7,stop_len = 10, is_qt = True, is_qc = True, qt = 0.9, qc = 0.85, metric_avg = 'binary', \\\n",
    "    need_strings = True)\n",
    "\n",
    "print(\"labels_fm shape: \", labels_fm.shape)\n",
    "print(\"labels_gm shape: \", labels_gm.shape)\n",
    "print(type(labels_fm[0]))\n",
    "print(type(labels_gm[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f5b4396ae54b339dce7091723dfd2c38ad833227f8e97d2a6323021886247d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
