{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import enum\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from spear.labeling import PreLabels\n",
    "import numpy as np\n",
    "from spear.cage import Cage\n",
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelling_function import *\n",
    "from PIL import Image\n",
    "from resnet18 import ResNet, BasicBlock\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from resnet18 import ResNet, BasicBlock\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring ClassLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = None\n",
    "\n",
    "class ClassLabels(enum.Enum):\n",
    "    LYMPHOCYTE= 0\n",
    "    NONLYMPHOCYTE = 1\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Labelling Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LFs for Class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n",
    "# path = \"/home/akshit/Desktop/MICCAI/data/models/\"\n",
    "path = \"/home/raja/Desktop/MICCAI/data/models/100/\"\n",
    "\n",
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'0_svmV11.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][0]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_V1, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_svm0_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'0_svmV11.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][0]>0.50: \n",
    "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_resnet_model(model_path):\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "def load_image_with_transform(input_img):\n",
    "    input_img = input_img.copy()\n",
    "    input_img = Image.fromarray(input_img)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    input_img = transform(input_img)\n",
    "    input_img = input_img.clone().detach().requires_grad_(True).to(torch.float)\n",
    "\n",
    "    #input_img = torch.tensor(input_img.clone().detach().requires_grad_(True), dtype=torch.float)\n",
    "    input_img = input_img.unsqueeze(0).to(device)\n",
    "\n",
    "    return input_img\n",
    "\n",
    "model_path = '/home/raja/Desktop/MICCAI/data/models/100/best.pkl'\n",
    "model = load_resnet_model(model_path)\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def ResNet18LF_NONLYMPHOCYTE(x,**kwargs):\n",
    "    input_image = load_image_with_transform(x)\n",
    "    output = model(input_image)\n",
    "    predicted_class = torch.argmax(output, dim=1)\n",
    "    confidence_scores = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "    if predicted_class.item() == 1 and confidence_scores[0][1] > 0.65:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_resnet_model(model_path):\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "def load_image_with_transform(input_img):\n",
    "    input_img = input_img.copy()\n",
    "    input_img = Image.fromarray(input_img)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "#sourceTensor.clone().detach().requires_grad_(True)\n",
    "    input_img = transform(input_img)\n",
    "    input_img = input_img.clone().detach().requires_grad_(True).to(torch.float)\n",
    "\n",
    "    #input_img = torch.tensor(input_img.clone().detach().requires_grad_(True), dtype=torch.float)\n",
    "    input_img = input_img.unsqueeze(0).to(device)\n",
    "\n",
    "    return input_img\n",
    "\n",
    "model_path = '/home/raja/Desktop/MICCAI/data/models/100/best.pkl'\n",
    "model = load_resnet_model(model_path)\n",
    "\n",
    "@labeling_function(label=ClassLabels.LYMPHOCYTE)\n",
    "def ResNet18LF_LYMPHOCYTE(x,**kwargs):\n",
    "    input_image = load_image_with_transform(x)\n",
    "    output = model(input_image)\n",
    "    predicted_class = torch.argmax(output, dim=1)\n",
    "    confidence_scores = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "    if predicted_class.item() == 0 and confidence_scores[0][0] > 0.50:\n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LFs for Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm1_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'1_svmV11.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm1_V1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_svm1_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'1_svmV11.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][1]>0.6: \n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelling_function import *\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL1(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if blue_score > 155:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL2(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    if 10 < blue_score < 180 and red_score > 170:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN    \n",
    "    \n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL9(c,**kwargs): \n",
    "    green_score = calculate_green_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    if 10 < blue_score < 180 and green_score > 155:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN      \n",
    "    \n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL3(c,**kwargs): \n",
    "    brown_score = compute_brown_score(c)\n",
    "    total_blue_score = compute_blue_score(c)\n",
    "    if total_blue_score < 12:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN   \n",
    "\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL4(c,**kwargs): \n",
    "    brown_score = compute_brown_score(c)\n",
    "    total_blue_score = compute_blue_score(c)\n",
    "    if brown_score > 585:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN   \n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL5(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if red_score > 170:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL6(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if red_score < 12:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL7(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if green_score > 155:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL8(c,**kwargs): \n",
    "    black_score = compute_black_score(c)\n",
    "    if black_score > 9:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN           \n",
    "\n",
    "    \n",
    "                 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating LFs & Labelling dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFSet\n",
    "Placeholder for declared LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import LFSet\n",
    "\n",
    "LFS = [\n",
    "    #ResNet18LF_LYMPHOCYTE,\n",
    "    #ResNet18LF_NONLYMPHOCYTE,\n",
    "    LFNL1,\n",
    "    LFNL2,\n",
    "    LFNL3,\n",
    "    LFNL4,\n",
    "    LFNL5,\n",
    "    LFNL6,\n",
    "    LFNL7,\n",
    "    LFNL8,\n",
    "    LFNL9,\n",
    "    \n",
    "    LF_svm0_V1,\n",
    "    LF_svm1_V1,  \n",
    "  \n",
    "]\n",
    "\n",
    "QT2 = 0.99\n",
    "QC2 = 0.99\n",
    "\n",
    "qt1 = np.array([0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999])\n",
    "qc1 = np.array([0.99999,0.99999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999])\n",
    "\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 17:08:18.856745: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 17:08:18.932589: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-24 17:08:19.257486: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/raja/Desktop/cage/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-05-24 17:08:19.257524: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/raja/Desktop/cage/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-05-24 17:08:19.257527: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "dataset,x,y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cage_loop(LFS, max_iters=10, threshold=10**-5, img_per_class = 150):\n",
    "    from keras.utils import np_utils\n",
    "    # Paths\n",
    "    log_path_cage = './cage_loop/log.txt' \n",
    "    params_path = None\n",
    "    path_json = \"./cage_loop/labels.json\"\n",
    "    U_path_pkl = \"./cage_loop/unlabelled.pkl\"\n",
    "    L_path_pkl = \"./cage_loop/labelled.pkl\"\n",
    "\n",
    "    # Loading Data\n",
    "    classes,label_frac,data_path,save_path = get_variables()\n",
    "    print(\"Classes used in expt:\",classes)\n",
    "    dataset,x,y = custom_dataset(classes=classes, path=data_path, fraction=label_frac)\n",
    "\n",
    "    xu = np.array(dataset['test_images'])\n",
    "    yu = np.array(dataset['test_labels'])\n",
    "    print(np.shape(xu),np.shape(yu))\n",
    "    # Creating rules\n",
    "    n_lfs = len(LFS)\n",
    "    rules = LFSet(\"BM_LF\")\n",
    "    rules.add_lf_list(LFS)\n",
    "    \n",
    "    confidence_list = []\n",
    "    val_scores = []\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        # Train Models in LFs\n",
    "        train_all_LF(x,y,len(classes),save_path,label_frac)\n",
    "\n",
    "        # Unlabelled\n",
    "        u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
    "                                    data=xu,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Lu,Su = u_noisy_labels.get_labels()\n",
    "        u_noisy_labels.generate_pickle(U_path_pkl)\n",
    "\n",
    "        # Labelled\n",
    "        l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
    "                                    data=x,\n",
    "                                    gold_labels=y,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Ll,Sl = l_noisy_labels.get_labels()\n",
    "        l_noisy_labels.generate_pickle(L_path_pkl)\n",
    "        l_noisy_labels.generate_json(path_json)\n",
    "\n",
    "\n",
    "        # Cage\n",
    "        cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
    "        if params_path is not None: \n",
    "            cage.load_params(load_path = params_path)\n",
    "        else:\n",
    "            params_path = './cage_loop/params.pkl' \n",
    "        \n",
    "        probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = L_path_pkl, path_log = log_path_cage, qt = QT2, qc = QC2, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
    "        labels = np.argmax(probs, 1)\n",
    "\n",
    "        print(labels)\n",
    "\n",
    "        values, frequency = np.unique(yu, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Lake Class {values}: {frequency}\")\n",
    "\n",
    "        values, frequency = np.unique(y, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Labelled Set {values}: {frequency}\")\n",
    "        \n",
    "        print(\"=\"*45)\n",
    "        print(\"Iteration\",i)\n",
    "        print(\"Shape of Labeled Data:\",x.shape)\n",
    "        print(\"Shape of Unlabeled Data:\",xu.shape)\n",
    "        print(\"Accuracy on unlabelled images:\",accuracy_score(labels,yu)*100)\n",
    "        print(\"=\"*45)\n",
    "        \n",
    "        cage.save_params(save_path = params_path)\n",
    "\n",
    "        confidence = np.array([np.max(i) for i in probs])\n",
    "        confidence_list.append(confidence)\n",
    "        print(i,probs.shape)\n",
    "\n",
    "        # Getting indices of probabilities in decreasing order\n",
    "        idx = np.argsort(confidence)\n",
    "        idx = idx[::-1] \n",
    "\n",
    "        # Number of images per class (5%)\n",
    "        # img_per_class = int(0.05*len(confidence)/len(classes))\n",
    "\n",
    "        # Number of images per class (50)\n",
    "        \n",
    "        \n",
    "        print(\"Num img per class =\",img_per_class)\n",
    "\n",
    "        pop_list = [] #list of indices of images to be added\n",
    "        label_count = []\n",
    "\n",
    "        for j in idx:\n",
    "            if confidence[j]>threshold and label_count.count(labels[j])<img_per_class:\n",
    "                pop_list.append(j)\n",
    "                label_count.append(labels[j])\n",
    "        \n",
    "        print(\"Number of images getting transferred:\", len(pop_list))\n",
    "        print('Accuracy of Pseudo-labelled img added to dataset:', accuracy_score(labels[pop_list],yu[pop_list])*100)\n",
    "        \n",
    "        x = np.append(x,xu[pop_list], axis=0)\n",
    "        y = np.append(y,labels[pop_list], axis=0)        \n",
    "        xu = np.delete(xu,pop_list, axis=0)\n",
    "        yu = np.delete(yu,pop_list, axis=0)\n",
    "\n",
    "        if len(pop_list)<5:\n",
    "            break\n",
    "\n",
    "        # Deleting variables\n",
    "        del u_noisy_labels\n",
    "        del l_noisy_labels\n",
    "        del cage\n",
    "\n",
    "        classes,label_frac,data_path,save_path = get_variables()\n",
    "\n",
    "\n",
    "    return x,y,xu,yu,confidence_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes used in expt: [0, 1]\n",
      "(2, 30, 30, 3) (2,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 334.42it/s]\n",
      "100%|██████████| 210/210 [00:00<00:00, 626.76it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 39.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_test_accuracy_score: 0.9523809523809523\n",
      "test_average_metric: macro\tfinal_test_f1_score: 0.9523420479302832\n",
      "[0 0]\n",
      "Labels of Lake Class 0: 1\n",
      "Labels of Lake Class 1: 1\n",
      "Labels of Labelled Set 0: 105\n",
      "Labels of Labelled Set 1: 105\n",
      "=============================================\n",
      "Iteration 0\n",
      "Shape of Labeled Data: (210, 30, 30, 3)\n",
      "Shape of Unlabeled Data: (2, 30, 30, 3)\n",
      "Accuracy on unlabelled images: 50.0\n",
      "=============================================\n",
      "0 (2, 2)\n",
      "Num img per class = 10\n",
      "Number of images getting transferred: 2\n",
      "Accuracy of Pseudo-labelled img added to dataset: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#  img_per_class: num images added per loop per class\n",
    "x,y,xu,yu,confidence_list = cage_loop(LFS, max_iters=1, threshold=10**-10,  img_per_class = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.00109503, 0.00109503])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31031/3000661952.py:16: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(image_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370437, 30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "image_folder = '/home/raja/Desktop/MICCAI/training_folder'\n",
    "\n",
    "#image_folder = '/home/raja/Desktop/segment-anything/output/NONLYM'\n",
    "#image_folder = '/home/raja/Desktop/segment-anything/output/TRAIN/LYMPHOCYTES'\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "image_data = []\n",
    "image_names = []\n",
    "for file in image_files:\n",
    "    image_path = os.path.join(image_folder, file)\n",
    "    image = imageio.imread(image_path)\n",
    "    resized_image = resize(image, (30, 30, 3))\n",
    "    image_data.append(resized_image)\n",
    "    image_names.append(file)\n",
    "\n",
    "xuu = (np.array(image_data) * 255).astype(np.uint8)\n",
    "\n",
    "print(xuu.shape)  # (num_images, 30, 30, 3)\n",
    "#print(image_names)  # list of image file names in the same order as x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 370437/370437 [08:41<00:00, 710.70it/s]\n",
      "100%|██████████| 210/210 [00:00<00:00, 691.90it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 26.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_test_accuracy_score: 0.9476190476190476\n",
      "test_average_metric: macro\tfinal_test_f1_score: 0.947560781821071\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import np_utils\n",
    "# Paths\n",
    "log_path_cage = './cage_loop/log.txt' \n",
    "params_path = None\n",
    "path_json = \"./cage_loop/labels.json\"\n",
    "U_path_pkl = \"./cage_loop/unlabelled.pkl\"\n",
    "L_path_pkl = \"./cage_loop/labelled.pkl\"\n",
    "\n",
    "# Loading Data\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "#print(\"Classes used in expt:\",classes)\n",
    "dataset,x,y = custom_dataset(classes=classes, path=data_path, fraction=label_frac)\n",
    "xu = np.array(dataset['test_images'])\n",
    "\n",
    "# Unlabelled\n",
    "u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
    "                            data=xuu,\n",
    "                            rules=rules,\n",
    "                            labels_enum=ClassLabels,\n",
    "                            num_classes=len(classes))\n",
    "# Lu,Su = u_noisy_labels.get_labels()\n",
    "u_noisy_labels.generate_pickle(U_path_pkl)\n",
    "\n",
    "# Labelled\n",
    "l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
    "                            data=x,\n",
    "                            gold_labels=y,\n",
    "                            rules=rules,\n",
    "                            labels_enum=ClassLabels,\n",
    "                            num_classes=len(classes))\n",
    "# Ll,Sl = l_noisy_labels.get_labels()\n",
    "l_noisy_labels.generate_pickle(L_path_pkl)\n",
    "l_noisy_labels.generate_json(path_json)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(np.shape(xuu))\n",
    "# Creating rules\n",
    "n_lfs = len(LFS)\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)\n",
    "\n",
    "# Cage\n",
    "cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
    "if params_path is not None: \n",
    "    cage.load_params(load_path = params_path)\n",
    "else:\n",
    "    params_path = './cage_loop/params.pkl' \n",
    "probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = L_path_pkl, path_log = log_path_cage, qt = QT2, qc = QC2, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
    "\n",
    "#probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = L_path_pkl, path_log = log_path_cage, qt = 0.9, qc = 0.85, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
    "labels = np.argmax(probs, 1)\n",
    "\n",
    "print(labels)\n",
    "\n",
    "# Define the file path to save the probabilities\n",
    "probs_file_path = '/home/raja/Desktop/MICCAI/probs.txt'\n",
    "\n",
    "# Save the probabilities to the text file\n",
    "np.savetxt(probs_file_path, probs)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31031/1530542732.py:16: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(image_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46376, 30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "image_folder = '/home/raja/Desktop/MICCAI/test_folder'\n",
    "\n",
    "#image_folder = '/home/raja/Desktop/segment-anything/output/NONLYM'\n",
    "#image_folder = '/home/raja/Desktop/segment-anything/output/TRAIN/LYMPHOCYTES'\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "image_data = []\n",
    "image_names = []\n",
    "for file in image_files:\n",
    "    image_path = os.path.join(image_folder, file)\n",
    "    image = imageio.imread(image_path)\n",
    "    resized_image = resize(image, (30, 30, 3))\n",
    "    image_data.append(resized_image)\n",
    "    image_names.append(file)\n",
    "\n",
    "xuu = (np.array(image_data) * 255).astype(np.uint8)\n",
    "\n",
    "print(xuu.shape)  # (num_images, 30, 30, 3)\n",
    "#print(image_names)  # list of image file names in the same order as x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46376/46376 [01:15<00:00, 616.38it/s]\n",
      "100%|██████████| 210/210 [00:00<00:00, 605.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Predict is used before training any paramters in Cage class. Hope you have loaded parameters.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "# Paths\n",
    "log_path_cage = './cage_loop/log.txt' \n",
    "params_path = None\n",
    "path_json = \"./cage_loop/labels.json\"\n",
    "U_path_pkl = \"./cage_loop/unlabelled.pkl\"\n",
    "L_path_pkl = \"./cage_loop/labelled.pkl\"\n",
    "\n",
    "# Loading Data\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "#print(\"Classes used in expt:\",classes)\n",
    "dataset,x,y = custom_dataset(classes=classes, path=data_path, fraction=label_frac)\n",
    "xu = np.array(dataset['test_images'])\n",
    "\n",
    "# Unlabelled\n",
    "u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
    "                            data=xuu,\n",
    "                            rules=rules,\n",
    "                            labels_enum=ClassLabels,\n",
    "                            num_classes=len(classes))\n",
    "# Lu,Su = u_noisy_labels.get_labels()\n",
    "u_noisy_labels.generate_pickle(U_path_pkl)\n",
    "\n",
    "# Labelled\n",
    "l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
    "                            data=x,\n",
    "                            gold_labels=y,\n",
    "                            rules=rules,\n",
    "                            labels_enum=ClassLabels,\n",
    "                            num_classes=len(classes))\n",
    "# Ll,Sl = l_noisy_labels.get_labels()\n",
    "l_noisy_labels.generate_pickle(L_path_pkl)\n",
    "l_noisy_labels.generate_json(path_json)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(np.shape(xuu))\n",
    "# Creating rules\n",
    "n_lfs = len(LFS)\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)\n",
    "\n",
    "# Cage\n",
    "cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
    "if params_path is not None: \n",
    "    cage.load_params(load_path = params_path)\n",
    "else:\n",
    "    params_path = './cage_loop/params.pkl' \n",
    "probs = cage.predict_proba(path_test = U_path_pkl, qc = QC2)    \n",
    "labels = np.argmax(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46376"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Combine image names and predicted labels\n",
    "data = zip(image_names, labels)\n",
    "\n",
    "# Write to CSV file\n",
    "with open('/home/raja/Desktop/MICCAI/predictions-train-SVM-HF-cage-prob.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Image Name', 'Label'])\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# Define input and output file names\n",
    "input_file = '/home/raja/Desktop/MICCAI/predictions-train-SVM-HF-cage-prob.csv'\n",
    "output_file = '/home/raja/Desktop/MICCAI/output-train-final-SVM-HF-prob.csv'\n",
    "\n",
    "# Define dictionary to store counts for each image\n",
    "image_counts = {}\n",
    "\n",
    "# Define regular expression to extract image number from filename\n",
    "img_regex = re.compile(r'img_(\\d+)_cropped_\\d+.jpg')\n",
    "\n",
    "# Read input file and count labels for each image\n",
    "with open(input_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header row\n",
    "    for row in reader:\n",
    "        image_name, label = row\n",
    "        img_match = img_regex.match(image_name)\n",
    "        if img_match:\n",
    "            image_number = int(img_match.group(1))\n",
    "            if image_number in image_counts:\n",
    "                if label == '0':\n",
    "                    image_counts[image_number][0] += 1\n",
    "                else:\n",
    "                    image_counts[image_number][1] += 1\n",
    "            else:\n",
    "                if label == '0':\n",
    "                    image_counts[image_number] = {0: 1, 1: 0}\n",
    "                else:\n",
    "                    image_counts[image_number] = {0: 0, 1: 1}\n",
    "\n",
    "# Write output file with counts for each image\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Image', 'Predicted-Lymphocyte', 'Non-Lymphocyte'])\n",
    "    for image_number, counts in sorted(image_counts.items()):\n",
    "        writer.writerow(['img_{}'.format(image_number), counts[0], counts[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('/home/raja/Desktop/MICCAI/output-train-final-SVM-HF-prob.csv')\n",
    "\n",
    "# Create a new DataFrame with the full range of image numbers (18000 to 19999)\n",
    "img_range = range(18000, 20000)\n",
    "new_df = pd.DataFrame({'Image': ['img_' + str(i) for i in img_range],\n",
    "                       'Predicted-Lymphocyte': 0,\n",
    "                       'Non-Lymphocyte': 0})\n",
    "\n",
    "# Merge the new DataFrame with the original DataFrame using a left join\n",
    "merged_df = pd.merge(new_df, df, on='Image', how='left')\n",
    "\n",
    "# Fill the NaN values with zeros\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "# Write the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('/home/raja/Desktop/MICCAI/new_file-itr2-prob.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the csv file into a pandas DataFrame\n",
    "df = pd.read_csv('/home/raja/Desktop/MICCAI/output-train-final-SVM-HF-prob.csv')\n",
    "\n",
    "# create a new DataFrame with the full range of image numbers\n",
    "img_range = range(2000)\n",
    "new_df = pd.DataFrame({'Image': ['img_' + str(i) for i in img_range], 'Predicted-Lymphocyte': 0})\n",
    "\n",
    "# merge the new DataFrame with the original DataFrame using a left join\n",
    "merged_df = pd.merge(new_df, df, on='Image', how='left')\n",
    "\n",
    "\n",
    "# write the merged DataFrame to a new csv file\n",
    "merged_df.to_csv('/home/raja/Desktop/MICCAI/new_file-itr2-prob.csv', index=False)\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_csv('/home/raja/Desktop/MICCAI/new_file-itr2-prob.csv')\n",
    "\n",
    "# Fill the 'predicted' column with 0 for NA values\n",
    "df['Predicted-Lymphocyte_y'].fillna(0, inplace=True)\n",
    "\n",
    "# Save the modified DataFrame back to Excel\n",
    "df.to_csv('/home/raja/Desktop/MICCAI/new_file-itr2-prob.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# read the input CSV file into a pandas dataframe\n",
    "df = pd.read_csv('/home/raja/Desktop/MICCAI/new_file-SVM-HF.csv')\n",
    "\n",
    "# define the function to assign class labels based on ground truth values\n",
    "def assign_class(gt):\n",
    "    if gt == 0:\n",
    "        return '0 (No lymphocytes)'\n",
    "    elif 1 <= gt <= 5:\n",
    "        return '1-5'\n",
    "    elif 6 <= gt <= 10:\n",
    "        return '6-10'\n",
    "    elif 11 <= gt <= 20:\n",
    "        return '11-20'\n",
    "    elif 21 <= gt <= 50:\n",
    "        return '21-50'\n",
    "    elif 51 <= gt <= 200:\n",
    "        return '51-200'\n",
    "    else:\n",
    "        return '>200'\n",
    "\n",
    "# assign class labels to ground truth values\n",
    "df['Ground-truth Class'] = df['Ground-truth'].apply(assign_class)\n",
    "\n",
    "# assign class labels to predicted values based on the constraints\n",
    "df['Predicted Class'] = df.apply(lambda row: assign_class(row['Predicted-Lymphocyte_y']), axis=1)\n",
    "\n",
    "# calculate the confusion matrix\n",
    "confusion_matrix = pd.crosstab(df['Ground-truth Class'], df['Predicted Class'])\n",
    "\n",
    "# define the desired order of the classes\n",
    "desired_order = ['0 (No lymphocytes)', '1-5', '6-10', '11-20', '21-50']\n",
    "\n",
    "# reindex the confusion matrix to match the desired order\n",
    "confusion_matrix = confusion_matrix.reindex(index=desired_order, columns=desired_order, fill_value=0)\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix)\n",
    "\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f5b4396ae54b339dce7091723dfd2c38ad833227f8e97d2a6323021886247d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
