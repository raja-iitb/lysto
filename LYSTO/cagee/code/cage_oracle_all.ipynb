{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0823 - accuracy: 0.3500 - val_loss: 1.1402 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 1.0457 - accuracy: 0.4750 - val_loss: 1.2024 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.0517 - accuracy: 0.4000 - val_loss: 1.2424 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.0940 - accuracy: 0.3250 - val_loss: 1.2289 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.0249 - accuracy: 0.3750 - val_loss: 1.2056 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.0333 - accuracy: 0.4250 - val_loss: 1.1640 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.9895 - accuracy: 0.5750 - val_loss: 1.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9751 - accuracy: 0.5000 - val_loss: 1.0590 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9528 - accuracy: 0.6000 - val_loss: 1.0028 - val_accuracy: 1.0000\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9573 - accuracy: 0.5750 - val_loss: 0.9549 - val_accuracy: 1.0000\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9516 - accuracy: 0.5500 - val_loss: 0.9241 - val_accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8799 - accuracy: 0.7000 - val_loss: 0.8989 - val_accuracy: 1.0000\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9046 - accuracy: 0.5750 - val_loss: 0.8759 - val_accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8662 - accuracy: 0.6500 - val_loss: 0.8376 - val_accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8652 - accuracy: 0.5250 - val_loss: 0.7854 - val_accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8481 - accuracy: 0.7000 - val_loss: 0.7148 - val_accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7835 - accuracy: 0.7500 - val_loss: 0.6477 - val_accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7905 - accuracy: 0.6500 - val_loss: 0.5705 - val_accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7916 - accuracy: 0.7000 - val_loss: 0.5172 - val_accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7201 - accuracy: 0.8250 - val_loss: 0.4631 - val_accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6977 - accuracy: 0.7500 - val_loss: 0.4198 - val_accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7446 - accuracy: 0.6750 - val_loss: 0.3931 - val_accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7086 - accuracy: 0.6750 - val_loss: 0.3802 - val_accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6925 - accuracy: 0.6250 - val_loss: 0.3601 - val_accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6312 - accuracy: 0.7500 - val_loss: 0.2899 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import enum\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from spear.labeling import PreLabels\n",
    "import numpy as np\n",
    "from spear.cage import Cage\n",
    "from utils import custom_dataset, train_all_LF, class_count\n",
    "from generate_LF import get_variables2\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "from cnn import create_cnn\n",
    "from keras.utils import np_utils\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring ClassLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = None\n",
    "\n",
    "class ClassLabels(enum.Enum):\n",
    "    BASOPHIL = 0\n",
    "    EOSINOPHIL = 1\n",
    "    ERYTHROBLAST = 2\n",
    "    IMG = 3\n",
    "    LYMPHOCYTE = 4\n",
    "    MONOCYTE = 5\n",
    "    NEUTROPHIL = 6\n",
    "    PLATELET = 7\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Labelling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\adity\\\\Documents\\\\GitHub\\\\MICCAI\\\\data2\\\\models\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_0(x,**kwargs):\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_svm_0(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_0(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_rf_0(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_0(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_knn_0(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_0(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_dt_0(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_0(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_lr_0(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_1(x,**kwargs):\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_svm_1(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_1(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_rf_1(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_1(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_knn_1(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_1(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_dt_1(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_1(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_lr_1(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_2(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'2_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_2, label=ClassLabels.ERYTHROBLAST)\n",
    "def LF_svm_2(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'2_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.ERYTHROBLAST\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_2(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'2_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_2, label=ClassLabels.ERYTHROBLAST)\n",
    "def LF_rf_2(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'2_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.ERYTHROBLAST\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_2(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'2_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_2, label=ClassLabels.ERYTHROBLAST)\n",
    "def LF_knn_2(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'2_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.ERYTHROBLAST\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_2(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'2_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_2, label=ClassLabels.ERYTHROBLAST)\n",
    "def LF_dt_2(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'2_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.ERYTHROBLAST\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_2(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'2_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_2, label=ClassLabels.ERYTHROBLAST)\n",
    "def LF_lr_2(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'2_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.ERYTHROBLAST\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_3(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'3_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_3, label=ClassLabels.IMG)\n",
    "def LF_svm_3(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'3_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.IMG\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_3(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'3_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_3, label=ClassLabels.IMG)\n",
    "def LF_rf_3(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'3_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.IMG\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_3(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'3_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_3, label=ClassLabels.IMG)\n",
    "def LF_knn_3(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'3_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.IMG\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_3(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'3_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_3, label=ClassLabels.IMG)\n",
    "def LF_dt_3(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'3_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.IMG\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_3(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'3_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_3, label=ClassLabels.IMG)\n",
    "def LF_lr_3(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'3_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.IMG\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_4(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'4_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_4, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_svm_4(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'4_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_4(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'4_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_4, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_rf_4(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'4_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_4(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'4_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_4, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_knn_4(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'4_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_4(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'4_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_4, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_dt_4(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'4_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_4(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'4_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_4, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_lr_4(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'4_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_5(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'5_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_5, label=ClassLabels.MONOCYTE)\n",
    "def LF_svm_5(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'5_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.MONOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_5(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'5_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_5, label=ClassLabels.MONOCYTE)\n",
    "def LF_rf_5(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'5_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.MONOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_5(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'5_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_5, label=ClassLabels.MONOCYTE)\n",
    "def LF_knn_5(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'5_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.MONOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_5(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'5_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_5, label=ClassLabels.MONOCYTE)\n",
    "def LF_dt_5(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'5_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.MONOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_5(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'5_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_5, label=ClassLabels.MONOCYTE)\n",
    "def LF_lr_5(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'5_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.MONOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_6(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'6_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_6, label=ClassLabels.NEUTROPHIL)\n",
    "def LF_svm_6(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'6_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NEUTROPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_6(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'6_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_6, label=ClassLabels.NEUTROPHIL)\n",
    "def LF_rf_6(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'6_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NEUTROPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_6(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'6_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_6, label=ClassLabels.NEUTROPHIL)\n",
    "def LF_knn_6(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'6_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NEUTROPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_6(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'6_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_6, label=ClassLabels.NEUTROPHIL)\n",
    "def LF_dt_6(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'6_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NEUTROPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_6(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'6_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_6, label=ClassLabels.NEUTROPHIL)\n",
    "def LF_lr_6(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'6_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NEUTROPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_7(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'7_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_7, label=ClassLabels.PLATELET)\n",
    "def LF_svm_7(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'7_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_7(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'7_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_7, label=ClassLabels.PLATELET)\n",
    "def LF_rf_7(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'7_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_7(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'7_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_7, label=ClassLabels.PLATELET)\n",
    "def LF_knn_7(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'7_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_7(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'7_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_7, label=ClassLabels.PLATELET)\n",
    "def LF_dt_7(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'7_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_7(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'7_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_7, label=ClassLabels.PLATELET)\n",
    "def LF_lr_7(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'7_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating LFs & Labelling dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFSet\n",
    "Placeholder for declared LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import LFSet\n",
    "\n",
    "LFS = [\n",
    "    LF_svm_0,\n",
    "    LF_rf_0,\n",
    "    LF_knn_0,\n",
    "    LF_dt_0,\n",
    "    LF_lr_0,\n",
    "    LF_svm_1,\n",
    "    LF_rf_1,\n",
    "    LF_knn_1,\n",
    "    LF_dt_1,\n",
    "    LF_lr_1,\n",
    "    LF_svm_2,\n",
    "    LF_rf_2,\n",
    "    LF_knn_2,\n",
    "    LF_dt_2,\n",
    "    LF_lr_2,\n",
    "    LF_svm_3,\n",
    "    LF_rf_3,\n",
    "    LF_knn_3,\n",
    "    LF_dt_3,\n",
    "    LF_lr_3,\n",
    "    LF_svm_4,\n",
    "    LF_rf_4,\n",
    "    LF_knn_4,\n",
    "    LF_dt_4,\n",
    "    LF_lr_4,\n",
    "    LF_svm_5,\n",
    "    LF_rf_5,\n",
    "    LF_knn_5,\n",
    "    LF_dt_5,\n",
    "    LF_lr_5,\n",
    "    LF_svm_6,\n",
    "    LF_rf_6,\n",
    "    LF_knn_6,\n",
    "    LF_dt_6,\n",
    "    LF_lr_6,\n",
    "    LF_svm_7,\n",
    "    LF_rf_7,\n",
    "    LF_knn_7,\n",
    "    LF_dt_7,\n",
    "    LF_lr_7,\n",
    "]\n",
    "\n",
    "\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "classes,label_frac,data_path,save_path = get_variables2()\n",
    "dataset,x,y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)\n",
    "yOracle = copy.deepcopy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map (curr, cls):\n",
    "    if curr==cls:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnScore(x, y,i):\n",
    "    x_train = np.array(x).reshape(-1, 28, 28, 3)\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    y_train = [int(i) for i in y]\n",
    "    y_train = np_utils.to_categorical(y_train, len(classes))\n",
    "\n",
    "    # Load Validation Data\n",
    "    # 5% of Val Set to Test CNN after every iteration\n",
    "    x_val, dummy1, y_val, dummy2 = train_test_split(dataset[\"val_images\"], dataset[\"val_labels\"], train_size=0.2)\n",
    "    x_val = np.array(x_val).reshape(-1, 28, 28, 3)\n",
    "    x_val = x_val.astype(\"float32\") / 255\n",
    "    y_val = [int(i) for i in y_val] \n",
    "    \n",
    "    # xv = []\n",
    "    # yv = []\n",
    "    # class_limit = int(0.05*len(dataset[\"val_labels\"])/len(classes))\n",
    "    # for j in range(len(classes)):\n",
    "    #     for i in range(len(y_val)):\n",
    "    #         if  yv.count(j) < class_limit and y_val[i] == j:\n",
    "    #             xv.append(x_val[i])\n",
    "    #             yv.append(y_val[i])\n",
    "\n",
    "    # print('*'*80)\n",
    "    # print([yv.count(i) for i in range(len(classes))])\n",
    "\n",
    "    xv = np.array(x_val)\n",
    "    yv = np.array(y_val)\n",
    "    yv = np_utils.to_categorical(yv, num_classes=len(classes))\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 25\n",
    "    model = create_cnn(num_classes = len(classes))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose = 0)\n",
    "    return model.evaluate(xv, yv, verbose = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cage_loop(LFS, max_iters=10, threshold=10**-5, img_per_class = 150):\n",
    "    # Paths\n",
    "    log_path_cage = './cage_loop2/log.txt' \n",
    "    params_path = None\n",
    "    path_json = \"./cage_loop2/labels.json\"\n",
    "    U_path_pkl = \"./cage_loop2/unlabelled.pkl\"\n",
    "    L_path_pkl = \"./cage_loop2/labelled.pkl\"\n",
    "\n",
    "    # Loading Data\n",
    "    classes,label_frac,data_path,save_path = get_variables2()\n",
    "    dataset,x,y = custom_dataset(classes=classes, path=data_path, fraction=label_frac)\n",
    "    xu = np.array(dataset['rem_images'])\n",
    "    yu = np.array(dataset['rem_labels'])\n",
    "    yOracle = copy.deepcopy(y)\n",
    "    \n",
    "    print(\"Classes used in expt:\",classes)\n",
    "\n",
    "    # Creating rules\n",
    "    n_lfs = len(LFS)\n",
    "    rules = LFSet(\"BM_LF\")\n",
    "    rules.add_lf_list(LFS)\n",
    "    \n",
    "    confidence_list = []\n",
    "    val_scores = []\n",
    "    oracle_val_scores = []\n",
    "    classwise_accuracies = []\n",
    "    pl_accuracies = []\n",
    "    for i in range(max_iters):\n",
    "        # Train Models in LFs\n",
    "        train_all_LF(x,y,len(classes),save_path,label_frac)\n",
    "\n",
    "        # Unlabelled\n",
    "        u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
    "                                    data=xu,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Lu,Su = u_noisy_labels.get_labels()\n",
    "        \n",
    "        u_noisy_labels.generate_pickle(U_path_pkl)\n",
    "        u_noisy_labels.generate_json(path_json)\n",
    "\n",
    "        # Labelled\n",
    "        # l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
    "        #                             data=x,\n",
    "        #                             gold_labels=y,\n",
    "        #                             rules=rules,\n",
    "        #                             labels_enum=ClassLabels,\n",
    "        #                             num_classes=len(classes))\n",
    "        # # Ll,Sl = l_noisy_labels.get_labels()\n",
    "        # l_noisy_labels.generate_pickle(L_path_pkl)\n",
    "        # l_noisy_labels.generate_json(path_json)\n",
    "\n",
    "\n",
    "        # Cage\n",
    "        cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
    "        if params_path is not None: \n",
    "            cage.load_params(load_path = params_path)\n",
    "        else:\n",
    "            params_path = './cage_loop2/params.pkl' \n",
    "        \n",
    "        probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_log = log_path_cage, qt = 0.9, qc = 0.85, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
    "        labels = np.argmax(probs, 1)\n",
    "\n",
    "        print(\"=\"*135)\n",
    "        print(\"Iteration\",i)\n",
    "        values, frequency = np.unique(yu, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Lake Class {values}: {frequency}\")\n",
    "\n",
    "        values, frequency = np.unique(y, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Labelled Set {values}: {frequency}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Shape of Labeled Data:\",x.shape)\n",
    "        print(\"Shape of Unlabeled Data:\",xu.shape)\n",
    "        print(\"Accuracy on unlabelled images:\",accuracy_score(labels,yu)*100)\n",
    "        \n",
    "        \n",
    "        cage.save_params(save_path = params_path)\n",
    "\n",
    "        confidence = np.array([np.max(i) for i in probs])\n",
    "        confidence_list.append(confidence)\n",
    "        print(i,probs.shape)\n",
    "\n",
    "        # Getting indices of probabilities in decreasing order\n",
    "        idx = np.argsort(confidence)\n",
    "        idx = idx[::-1] \n",
    "\n",
    "        # Number of images per class (5%)\n",
    "        # img_per_class = int(0.05*len(confidence)/len(classes))\n",
    "\n",
    "        # Number of images per class (50)\n",
    "        \n",
    "        \n",
    "        print(\"Num img per class =\",img_per_class)\n",
    "\n",
    "        pop_list = [] #list of indices of images to be added\n",
    "        label_count = []\n",
    "        threshcount = 0\n",
    "        unl = []\n",
    "        for j in idx:\n",
    "            if confidence[j]>threshold:\n",
    "                threshcount+=1\n",
    "                unl.append(labels[j])\n",
    "\n",
    "            if confidence[j]>threshold and label_count.count(labels[j])<img_per_class:\n",
    "                pop_list.append(j)\n",
    "                label_count.append(labels[j])\n",
    "        \n",
    "        print(\"Number of images above threshold:\",threshcount)\n",
    "        print(\"Classes of images above threshold:\",set(unl))\n",
    "        print(\"Number of images getting transferred:\", len(pop_list))\n",
    "        print('Accuracy of Pseudo-labelled img added to dataset:', accuracy_score(labels[pop_list],yu[pop_list])*100)\n",
    "        pl_accuracies.append(accuracy_score(labels[pop_list],yu[pop_list])*100)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cmidx = [[(map(yu[j],i), map(labels[j],i)) for j in range(len(labels))] for i in range(len(classes))]\n",
    "        cacc = []\n",
    "        fig, ax = plt.subplots(math.ceil(len(classes)/2),2, figsize=(15, 20))\n",
    "        pltnum = 0\n",
    "        for cmid in cmidx:\n",
    "            cacc.append(accuracy_score([z[0] for z in cmid], [z[1] for z in cmid])*100)\n",
    "            ax[pltnum//2,pltnum%2].set_title(f\"Class {pltnum}\")\n",
    "            confusion_matrix = metrics.confusion_matrix([z[0] for z in cmid], [z[1] for z in cmid])\n",
    "            cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "            cm_display.plot(ax=ax[pltnum//2,pltnum%2])\n",
    "            pltnum += 1\n",
    "        classwise_accuracies.append(cacc)\n",
    "        fig.suptitle(f\"Iteration {i}\")\n",
    "        plt.show()\n",
    "        plt.savefig(f\"all_cm_iteration_{i}.jpg\")\n",
    "\n",
    "        if len(pop_list)<50:\n",
    "            break\n",
    "        \n",
    "        x = np.append(x,xu[pop_list], axis=0)\n",
    "        y = np.append(y,labels[pop_list], axis=0)\n",
    "        yOracle = np.append(yOracle,yu[pop_list], axis=0)\n",
    "        xu = np.delete(xu,pop_list, axis=0)\n",
    "        yu = np.delete(yu,pop_list, axis=0)\n",
    "\n",
    "        # Deleting variables\n",
    "        del u_noisy_labels\n",
    "        del cage\n",
    "\n",
    "        classes,label_frac,data_path,save_path = get_variables2()\n",
    "\n",
    "        val_scores.append(cnnScore(x, y,i)[1]*100)\n",
    "        oracle_val_scores.append(cnnScore(x,yOracle,i)[1]*100)\n",
    "        print(f\"CNN Val accuracy trained on Lake Set for iteration {i}: \", val_scores[i])\n",
    "        print(f\"CNN Val accuracy trained on Oracle for iteration {i}: \", oracle_val_scores[i])\n",
    "\n",
    "        # for j in range(len(classes)):\n",
    "        #     if label_count.count(j)<75:\n",
    "        #         print(\"*\"*60+\"Predicted Break\"+\"*\"*60)\n",
    "        #         break\n",
    "\n",
    "        \n",
    "        print(\"=\"*135)\n",
    "        # if i>0 and val_scores[i]<val_scores[i-1]:\n",
    "        #     break\n",
    "\n",
    "\n",
    "    return x,y,xu,yu,confidence_list, val_scores, oracle_val_scores, classwise_accuracies, pl_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes used in expt: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5908/11127 [57:09<50:29,  1.72it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#  img_per_class: num images added per loop per class\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x,y,xu,yu,confidence_list, val_scores, oracle_val_scores, classwise_accuracies, pl_accuracies \u001b[39m=\u001b[39m cage_loop(LFS, max_iters\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m, threshold\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m5\u001b[39;49m,  img_per_class \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[29], line 40\u001b[0m, in \u001b[0;36mcage_loop\u001b[1;34m(LFS, max_iters, threshold, img_per_class)\u001b[0m\n\u001b[0;32m     33\u001b[0m u_noisy_labels \u001b[39m=\u001b[39m PreLabels(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbmnist_rem_ul\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m                             data\u001b[39m=\u001b[39mxu,\n\u001b[0;32m     35\u001b[0m                             rules\u001b[39m=\u001b[39mrules,\n\u001b[0;32m     36\u001b[0m                             labels_enum\u001b[39m=\u001b[39mClassLabels,\n\u001b[0;32m     37\u001b[0m                             num_classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(classes))\n\u001b[0;32m     38\u001b[0m \u001b[39m# Lu,Su = u_noisy_labels.get_labels()\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m u_noisy_labels\u001b[39m.\u001b[39;49mgenerate_pickle(U_path_pkl)\n\u001b[0;32m     41\u001b[0m u_noisy_labels\u001b[39m.\u001b[39mgenerate_json(path_json)\n\u001b[0;32m     43\u001b[0m \u001b[39m# Labelled\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m# l_noisy_labels = PreLabels(name=\"bmnist_l\",\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m#                             data=x,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \n\u001b[0;32m     55\u001b[0m \u001b[39m# Cage\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\spear\\labeling\\prelabels\\core.py:125\u001b[0m, in \u001b[0;36mPreLabels.generate_pickle\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_L \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_S \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    124\u001b[0m     applier \u001b[39m=\u001b[39m LFApplier(lf_set \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rules)\n\u001b[1;32m--> 125\u001b[0m     L,S \u001b[39m=\u001b[39m applier\u001b[39m.\u001b[39;49mapply(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data)\n\u001b[0;32m    126\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_L \u001b[39m=\u001b[39m L\n\u001b[0;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_S \u001b[39m=\u001b[39m S\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\spear\\labeling\\apply\\core.py:163\u001b[0m, in \u001b[0;36mLFApplier.apply\u001b[1;34m(self, data_points, progress_bar, fault_tolerant, return_meta)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data_points)) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m    162\u001b[0m         \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_points):\n\u001b[1;32m--> 163\u001b[0m             labels\u001b[39m.\u001b[39mappend(apply_lfs_to_data_point(x, i, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lfs, f_caller))\n\u001b[0;32m    164\u001b[0m             pbar\u001b[39m.\u001b[39mupdate()\n\u001b[0;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\spear\\labeling\\apply\\core.py:102\u001b[0m, in \u001b[0;36mapply_lfs_to_data_point\u001b[1;34m(x, index, lfs, f_caller)\u001b[0m\n\u001b[0;32m    100\u001b[0m labels \u001b[39m=\u001b[39m []\n\u001b[0;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m j, lf \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(lfs):\n\u001b[1;32m--> 102\u001b[0m     y, z \u001b[39m=\u001b[39m f_caller(lf, x)\n\u001b[0;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m (y\u001b[39m==\u001b[39mABSTAIN \u001b[39mand\u001b[39;00m z \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    104\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\spear\\labeling\\apply\\core.py:30\u001b[0m, in \u001b[0;36m_FunctionCaller.__call__\u001b[1;34m(self, f, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, f: LabelingFunction, x: DataPoint):\n\u001b[0;32m     29\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfault_tolerant:\n\u001b[1;32m---> 30\u001b[0m         \u001b[39mreturn\u001b[39;00m f(x)\n\u001b[0;32m     31\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m         \u001b[39mreturn\u001b[39;00m f(x)\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\spear\\labeling\\lf\\core.py:75\u001b[0m, in \u001b[0;36mLabelingFunction.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     73\u001b[0m     cs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cont_scorer(x,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resources)     \u001b[39m# continuous score\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     dic \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcontinuous_score\u001b[39m\u001b[39m\"\u001b[39m: cs}\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_f(x,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdic), cs\n\u001b[0;32m     76\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     cs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 48\u001b[0m, in \u001b[0;36mLF_knn_6\u001b[1;34m(x, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(x)\u001b[39m.\u001b[39mflatten()  \n\u001b[0;32m     47\u001b[0m knn \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m6_knn.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m---> 48\u001b[0m \u001b[39mif\u001b[39;00m knn\u001b[39m.\u001b[39;49mpredict_proba([x])[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m>\u001b[39m\u001b[39m0.8\u001b[39m: \n\u001b[0;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m ClassLabels\u001b[39m.\u001b[39mNEUTROPHIL\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m: \n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:256\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    241\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return probability estimates for the test data X.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \n\u001b[0;32m    243\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39m        by lexicographic order.\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     neigh_dist, neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X)\n\u001b[0;32m    258\u001b[0m     classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m    259\u001b[0m     _y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\sklearn\\neighbors\\_base.py:752\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    750\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 752\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m    753\u001b[0m         pairwise_distances_chunked(\n\u001b[0;32m    754\u001b[0m             X,\n\u001b[0;32m    755\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[0;32m    756\u001b[0m             reduce_func\u001b[39m=\u001b[39;49mreduce_func,\n\u001b[0;32m    757\u001b[0m             metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[0;32m    758\u001b[0m             n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    759\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[0;32m    760\u001b[0m         )\n\u001b[0;32m    761\u001b[0m     )\n\u001b[0;32m    763\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    764\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1717\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1715\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1716\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[1;32m-> 1717\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39mmetric, n_jobs\u001b[39m=\u001b[39mn_jobs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m   1718\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1719\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1721\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1889\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1886\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m   1887\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m-> 1889\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1430\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1427\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1429\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 1430\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m   1432\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1433\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:302\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meuclidean_distances\u001b[39m(\n\u001b[0;32m    227\u001b[0m     X, Y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, Y_norm_squared\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, X_norm_squared\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    228\u001b[0m ):\n\u001b[0;32m    229\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m    Compute the distance matrix between each pair from a vector array X and Y.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39m           [1.41421356]])\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m     X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m    304\u001b[0m     \u001b[39mif\u001b[39;00m X_norm_squared \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m         X_norm_squared \u001b[39m=\u001b[39m check_array(X_norm_squared, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:164\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    157\u001b[0m         X,\n\u001b[0;32m    158\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[1;32m--> 164\u001b[0m     Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    165\u001b[0m         Y,\n\u001b[0;32m    166\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    167\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    168\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    169\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    170\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    171\u001b[0m     )\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m precomputed:\n\u001b[0;32m    174\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  img_per_class: num images added per loop per class\n",
    "x,y,xu,yu,confidence_list, val_scores, oracle_val_scores, classwise_accuracies, pl_accuracies = cage_loop(LFS, max_iters=15, threshold=10**-5,  img_per_class = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43.75,\n",
       " 57.499998807907104,\n",
       " 68.75,\n",
       " 80.0000011920929,\n",
       " 82.4999988079071,\n",
       " 87.5,\n",
       " 85.00000238418579,\n",
       " 88.7499988079071,\n",
       " 92.5000011920929,\n",
       " 91.25000238418579]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_scores\n",
    "oracle_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([val_scores,oracle_val_scores,pl_accuracies], columns=[f'Iteration {i}' for i in range(len(val_scores))], index=['Our Results','Oracle/Skyline',\"Pseudo Labelled\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration 0</th>\n",
       "      <th>Iteration 1</th>\n",
       "      <th>Iteration 2</th>\n",
       "      <th>Iteration 3</th>\n",
       "      <th>Iteration 4</th>\n",
       "      <th>Iteration 5</th>\n",
       "      <th>Iteration 6</th>\n",
       "      <th>Iteration 7</th>\n",
       "      <th>Iteration 8</th>\n",
       "      <th>Iteration 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Our Results</th>\n",
       "      <td>44.999999</td>\n",
       "      <td>58.749998</td>\n",
       "      <td>62.50</td>\n",
       "      <td>63.749999</td>\n",
       "      <td>61.250001</td>\n",
       "      <td>64.999998</td>\n",
       "      <td>67.500001</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>66.250002</td>\n",
       "      <td>66.250002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle/Skyline</th>\n",
       "      <td>43.750000</td>\n",
       "      <td>57.499999</td>\n",
       "      <td>68.75</td>\n",
       "      <td>80.000001</td>\n",
       "      <td>82.499999</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>85.000002</td>\n",
       "      <td>88.749999</td>\n",
       "      <td>92.500001</td>\n",
       "      <td>91.250002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Iteration 0  Iteration 1  Iteration 2  Iteration 3  \\\n",
       "Our Results       44.999999    58.749998        62.50    63.749999   \n",
       "Oracle/Skyline    43.750000    57.499999        68.75    80.000001   \n",
       "\n",
       "                Iteration 4  Iteration 5  Iteration 6  Iteration 7  \\\n",
       "Our Results       61.250001    64.999998    67.500001    62.500000   \n",
       "Oracle/Skyline    82.499999    87.500000    85.000002    88.749999   \n",
       "\n",
       "                Iteration 8  Iteration 9  \n",
       "Our Results       66.250002    66.250002  \n",
       "Oracle/Skyline    92.500001    91.250002  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemblelf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65b9741ba6eaae6d85890be96456298c2d24fb14f0ef87b0a39bd8b2cf5b4454"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
