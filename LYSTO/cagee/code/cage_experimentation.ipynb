{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import enum\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from spear.labeling import PreLabels\n",
    "import numpy as np\n",
    "from spear.cage import Cage\n",
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring ClassLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = None\n",
    "\n",
    "class ClassLabels(enum.Enum):\n",
    "    BASOPHIL = 0\n",
    "    EOSINOPHIL = 1\n",
    "    PLATELET = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Labelling Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LFs for Class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n",
    "path = \"/home/akshit/Desktop/MICCAI/data/models/\"\n",
    "\n",
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_svm_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_rf_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    \n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_knn_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    \n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_dt_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    \n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_lr_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    \n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LFs for Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_svm_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_rf_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    \n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_knn_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    \n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_dt_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    \n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_lr_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    \n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LFs for Class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_2(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'2_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_2, label=ClassLabels.PLATELET)\n",
    "def LF_svm_2(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'2_svm.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_2(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'2_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_2, label=ClassLabels.PLATELET)\n",
    "def LF_rf_2(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'2_rf.pkl','rb'))\n",
    "    \n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_2(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'2_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_2, label=ClassLabels.PLATELET)\n",
    "def LF_knn_2(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'2_knn.pkl','rb'))\n",
    "    \n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_2(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'2_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_2, label=ClassLabels.PLATELET)\n",
    "def LF_dt_2(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'2_dtc.pkl','rb'))\n",
    "    \n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_2(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'2_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_2, label=ClassLabels.PLATELET)\n",
    "def LF_lr_2(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'2_lr.pkl','rb'))\n",
    "    \n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating LFs & Labelling dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFSet\n",
    "Placeholder for declared LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import LFSet\n",
    "\n",
    "LFS = [\n",
    "    LF_svm_0,\n",
    "    LF_rf_0,\n",
    "    LF_knn_0,\n",
    "    LF_dt_0,\n",
    "    LF_lr_0,\n",
    "    LF_svm_1,\n",
    "    LF_rf_1,\n",
    "    LF_knn_1,\n",
    "    LF_dt_1,\n",
    "    LF_lr_1,\n",
    "    LF_svm_2,\n",
    "    LF_rf_2,\n",
    "    LF_knn_2,\n",
    "    LF_dt_2,\n",
    "    LF_lr_2,    \n",
    "]\n",
    "\n",
    "\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables\n",
    "import numpy as np\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "dataset,x,y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cage_loop(LFS, max_iters=10, threshold=10**-5):\n",
    "    # Paths\n",
    "    log_path_cage = './cage_loop/log.txt' \n",
    "    params_path = None\n",
    "    path_json = \"./cage_loop/labels.json\"\n",
    "    U_path_pkl = \"./cage_loop/unlabelled.pkl\"\n",
    "    L_path_pkl = \"./cage_loop/labelled.pkl\"\n",
    "\n",
    "    # Loading Data\n",
    "    classes,label_frac,data_path,save_path = get_variables()\n",
    "    print(\"Classes used in expt:\",classes)\n",
    "    dataset,x,y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)\n",
    "    xu = np.array(dataset['rem_images'])\n",
    "    yu = np.array(dataset['rem_labels'])\n",
    "\n",
    "    # Creating rules\n",
    "    n_lfs = len(LFS)\n",
    "    rules = LFSet(\"BM_LF\")\n",
    "    rules.add_lf_list(LFS)\n",
    "\n",
    "    confidence_list = []\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        # Train Models in LFs\n",
    "        train_all_LF(x,y,len(classes),save_path,label_frac)\n",
    "\n",
    "        # Unlabelled\n",
    "        u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
    "                                    data=xu,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Lu,Su = u_noisy_labels.get_labels()\n",
    "        u_noisy_labels.generate_pickle(U_path_pkl)\n",
    "\n",
    "        # Labelled\n",
    "        l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
    "                                    data=x,\n",
    "                                    gold_labels=y,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Ll,Sl = l_noisy_labels.get_labels()\n",
    "        l_noisy_labels.generate_pickle(L_path_pkl)\n",
    "        l_noisy_labels.generate_json(path_json)\n",
    "\n",
    "\n",
    "        # Cage\n",
    "        cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
    "        if params_path is not None: \n",
    "            cage.load_params(load_path = params_path)\n",
    "        else:\n",
    "            params_path = './cage_loop/params.pkl' \n",
    "        \n",
    "        probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = L_path_pkl, path_log = log_path_cage, qt = 0.9, qc = 0.85, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
    "        labels = np.argmax(probs, 1)\n",
    "\n",
    "        values, frequency = np.unique(yu, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Lake Class {values}: {frequency}\")\n",
    "\n",
    "        values, frequency = np.unique(y, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Labelled Set {values}: {frequency}\")\n",
    "        \n",
    "        print(\"=\"*45)\n",
    "        print(\"Iteration\",i)\n",
    "        print(\"Shape of Labeled Data:\",x.shape)\n",
    "        print(\"Shape of Unlabeled Data:\",xu.shape)\n",
    "        print(\"Accuracy on unlabelled images:\",accuracy_score(labels,yu)*100)\n",
    "        print(\"=\"*45)\n",
    "        \n",
    "        cage.save_params(save_path = params_path)\n",
    "\n",
    "        confidence = np.array([np.max(i) for i in probs])\n",
    "        confidence_list.append(confidence)\n",
    "        print(i,probs.shape)\n",
    "\n",
    "        # Getting indices of probabilities in decreasing order\n",
    "        idx = np.argsort(confidence)\n",
    "        idx = idx[::-1] \n",
    "\n",
    "        # Number of images per class (5%)\n",
    "        img_per_class = int(0.05*len(confidence)/len(classes))\n",
    "        print(\"Num img per class =\",img_per_class)\n",
    "\n",
    "        pop_list = [] #list of indices of images to be added\n",
    "        label_count = []\n",
    "\n",
    "        for j in idx:\n",
    "            if confidence[j]>threshold and label_count.count(labels[j])<img_per_class:\n",
    "                pop_list.append(j)\n",
    "                label_count.append(labels[j])\n",
    "        \n",
    "        print(\"Number of images getting transferred:\", len(pop_list))\n",
    "        print('Accuracy of Pseudo-labelled img added to dataset:', accuracy_score(labels[pop_list],yu[pop_list])*100)\n",
    "        \n",
    "        x = np.append(x,xu[pop_list], axis=0)\n",
    "        y = np.append(y,labels[pop_list], axis=0)        \n",
    "        xu = np.delete(xu,pop_list, axis=0)\n",
    "        yu = np.delete(yu,pop_list, axis=0)\n",
    "\n",
    "        if len(pop_list)<50:\n",
    "            break\n",
    "        # Deleting variables\n",
    "        del u_noisy_labels\n",
    "        del l_noisy_labels\n",
    "        del cage\n",
    "\n",
    "    return x,y,xu,yu,confidence_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes used in expt: [0, 1, 7]\n",
      "{0, -1}\n",
      "Trained & Saved 6 models\n",
      "{1, -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshit/Desktop/ensemblelf/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/akshit/Desktop/ensemblelf/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n",
      "{2, -1}\n",
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10997907 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but SVC is expecting 2352 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x,y,xu,yu,confidence_list \u001b[39m=\u001b[39m cage_loop(LFS, max_iters\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m, threshold\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[17], line 34\u001b[0m, in \u001b[0;36mcage_loop\u001b[0;34m(LFS, max_iters, threshold)\u001b[0m\n\u001b[1;32m     28\u001b[0m u_noisy_labels \u001b[39m=\u001b[39m PreLabels(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbmnist_rem_ul\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m                             data\u001b[39m=\u001b[39mxu,\n\u001b[1;32m     30\u001b[0m                             rules\u001b[39m=\u001b[39mrules,\n\u001b[1;32m     31\u001b[0m                             labels_enum\u001b[39m=\u001b[39mClassLabels,\n\u001b[1;32m     32\u001b[0m                             num_classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(classes))\n\u001b[1;32m     33\u001b[0m \u001b[39m# Lu,Su = u_noisy_labels.get_labels()\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m u_noisy_labels\u001b[39m.\u001b[39;49mgenerate_pickle(U_path_pkl)\n\u001b[1;32m     36\u001b[0m \u001b[39m# Labelled\u001b[39;00m\n\u001b[1;32m     37\u001b[0m l_noisy_labels \u001b[39m=\u001b[39m PreLabels(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbmnist_l\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m                             data\u001b[39m=\u001b[39mx,\n\u001b[1;32m     39\u001b[0m                             gold_labels\u001b[39m=\u001b[39my,\n\u001b[1;32m     40\u001b[0m                             rules\u001b[39m=\u001b[39mrules,\n\u001b[1;32m     41\u001b[0m                             labels_enum\u001b[39m=\u001b[39mClassLabels,\n\u001b[1;32m     42\u001b[0m                             num_classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(classes))\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/spear/labeling/prelabels/core.py:125\u001b[0m, in \u001b[0;36mPreLabels.generate_pickle\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_L \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_S \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    124\u001b[0m     applier \u001b[39m=\u001b[39m LFApplier(lf_set \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rules)\n\u001b[0;32m--> 125\u001b[0m     L,S \u001b[39m=\u001b[39m applier\u001b[39m.\u001b[39;49mapply(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data)\n\u001b[1;32m    126\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_L \u001b[39m=\u001b[39m L\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_S \u001b[39m=\u001b[39m S\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/spear/labeling/apply/core.py:163\u001b[0m, in \u001b[0;36mLFApplier.apply\u001b[0;34m(self, data_points, progress_bar, fault_tolerant, return_meta)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data_points)) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m    162\u001b[0m         \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_points):\n\u001b[0;32m--> 163\u001b[0m             labels\u001b[39m.\u001b[39mappend(apply_lfs_to_data_point(x, i, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lfs, f_caller))\n\u001b[1;32m    164\u001b[0m             pbar\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/spear/labeling/apply/core.py:102\u001b[0m, in \u001b[0;36mapply_lfs_to_data_point\u001b[0;34m(x, index, lfs, f_caller)\u001b[0m\n\u001b[1;32m    100\u001b[0m labels \u001b[39m=\u001b[39m []\n\u001b[1;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m j, lf \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(lfs):\n\u001b[0;32m--> 102\u001b[0m     y, z \u001b[39m=\u001b[39m f_caller(lf, x)\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m (y\u001b[39m==\u001b[39mABSTAIN \u001b[39mand\u001b[39;00m z \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    104\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/spear/labeling/apply/core.py:30\u001b[0m, in \u001b[0;36m_FunctionCaller.__call__\u001b[0;34m(self, f, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, f: LabelingFunction, x: DataPoint):\n\u001b[1;32m     29\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfault_tolerant:\n\u001b[0;32m---> 30\u001b[0m         \u001b[39mreturn\u001b[39;00m f(x)\n\u001b[1;32m     31\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m         \u001b[39mreturn\u001b[39;00m f(x)\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/spear/labeling/lf/core.py:73\u001b[0m, in \u001b[0;36mLabelingFunction.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess_data_point(x)\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_cont:\n\u001b[0;32m---> 73\u001b[0m     cs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cont_scorer(x,\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resources)     \u001b[39m# continuous score\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     dic \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcontinuous_score\u001b[39m\u001b[39m\"\u001b[39m: cs}\n\u001b[1;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_f(x,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resources, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdic), cs\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/spear/labeling/continuous_scoring/core.py:36\u001b[0m, in \u001b[0;36mBaseContinuousScorer.__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x: DataPoint, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m     28\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Applies core function on datapoint to give continuous score\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39m        float: continuous score output by the function\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cf(x,\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m, in \u001b[0;36msvm_0\u001b[0;34m(x, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(x)\u001b[39m.\u001b[39mflatten() \u001b[39m# x is 28x28x3 input img \u001b[39;00m\n\u001b[1;32m     12\u001b[0m svm \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m0_svm.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m---> 13\u001b[0m confidence_scores \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39;49mpredict_proba([x])\n\u001b[1;32m     14\u001b[0m \u001b[39m# print(confidence_scores)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39m(confidence_scores[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/sklearn/utils/metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[1;32m    112\u001b[0m     \u001b[39m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(obj, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/sklearn/svm/_base.py:834\u001b[0m, in \u001b[0;36mBaseSVC.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[39m@available_if\u001b[39m(_check_proba)\n\u001b[1;32m    808\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    809\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \n\u001b[1;32m    811\u001b[0m \u001b[39m    The model need to have probability information computed at training\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[39m    datasets.\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 834\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_for_predict(X)\n\u001b[1;32m    835\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobA_\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobB_\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    836\u001b[0m         \u001b[39mraise\u001b[39;00m NotFittedError(\n\u001b[1;32m    837\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mpredict_proba is not available when fitted with probability=False\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    838\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/sklearn/svm/_base.py:592\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    589\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[0;32m--> 592\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    593\u001b[0m         X,\n\u001b[1;32m    594\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    595\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    596\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    597\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    598\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    601\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n\u001b[1;32m    602\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    587\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/ensemblelf/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features, but SVC is expecting 2352 features as input."
     ]
    }
   ],
   "source": [
    "x,y,xu,yu,confidence_list = cage_loop(LFS, max_iters=7, threshold=10**-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram of the data\n",
    "plt.hist(unconfident_labels, bins=10)\n",
    "\n",
    "# Set plot title and axis labels\n",
    "plt.title('Distribution of Normalised Confidences below 0.95')\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_pred = np.where(yu != labels)[0]\n",
    "# print(incorrect_pred)\n",
    "# print(confidence[incorrect_pred])\n",
    "\n",
    "incorrect_confidence = confidence[incorrect_pred]\n",
    "print(len(incorrect_confidence[incorrect_confidence>0.95]))\n",
    "print(len(incorrect_confidence))\n",
    "\n",
    "plt.hist(incorrect_confidence, bins=10)\n",
    "\n",
    "# Set plot title and axis labels\n",
    "plt.title('Distribution of Incorrect Confidences')\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import LFAnalysis\n",
    "\n",
    "analyse = l_noisy_labels.analyse_lfs(plot=True)\n",
    "\n",
    "result = analyse.head(16)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemblelf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65b9741ba6eaae6d85890be96456298c2d24fb14f0ef87b0a39bd8b2cf5b4454"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
