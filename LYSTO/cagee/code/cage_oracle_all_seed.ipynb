{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\Documents\\GitHub\\MICCAI\\med\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0823 - accuracy: 0.3500 - val_loss: 1.1402 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0457 - accuracy: 0.4750 - val_loss: 1.2024 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0517 - accuracy: 0.4000 - val_loss: 1.2424 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0940 - accuracy: 0.3250 - val_loss: 1.2289 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0249 - accuracy: 0.3750 - val_loss: 1.2056 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0333 - accuracy: 0.4250 - val_loss: 1.1640 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9895 - accuracy: 0.5750 - val_loss: 1.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9751 - accuracy: 0.5000 - val_loss: 1.0590 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9528 - accuracy: 0.6000 - val_loss: 1.0028 - val_accuracy: 1.0000\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9573 - accuracy: 0.5750 - val_loss: 0.9549 - val_accuracy: 1.0000\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9516 - accuracy: 0.5500 - val_loss: 0.9241 - val_accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8799 - accuracy: 0.7000 - val_loss: 0.8989 - val_accuracy: 1.0000\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9046 - accuracy: 0.5750 - val_loss: 0.8759 - val_accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8662 - accuracy: 0.6500 - val_loss: 0.8376 - val_accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8652 - accuracy: 0.5250 - val_loss: 0.7854 - val_accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8481 - accuracy: 0.7000 - val_loss: 0.7148 - val_accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7835 - accuracy: 0.7500 - val_loss: 0.6477 - val_accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7905 - accuracy: 0.6500 - val_loss: 0.5705 - val_accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7916 - accuracy: 0.7000 - val_loss: 0.5172 - val_accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7201 - accuracy: 0.8250 - val_loss: 0.4631 - val_accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6977 - accuracy: 0.7500 - val_loss: 0.4198 - val_accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7446 - accuracy: 0.6750 - val_loss: 0.3931 - val_accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7086 - accuracy: 0.6750 - val_loss: 0.3802 - val_accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6925 - accuracy: 0.6250 - val_loss: 0.3601 - val_accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6312 - accuracy: 0.7500 - val_loss: 0.2899 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import enum\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from spear.labeling import PreLabels\n",
    "import numpy as np\n",
    "from spear.cage import Cage\n",
    "from utils import custom_dataset, train_all_LF, class_count\n",
    "from generate_LF import get_variables2\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "from cnn import create_cnn\n",
    "from keras.utils import np_utils\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring ClassLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = None\n",
    "\n",
    "class ClassLabels(enum.Enum):\n",
    "    BASOPHIL = 0\n",
    "    EOSINOPHIL = 1\n",
    "    ERYTHROBLAST = 2\n",
    "    IMG = 3\n",
    "    LYMPHOCYTE = 4\n",
    "    MONOCYTE = 5\n",
    "    NEUTROPHIL = 6\n",
    "    PLATELET = 7\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Labelling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\adity\\\\Documents\\\\GitHub\\\\MICCAI\\\\data2\\\\models\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_0(x,**kwargs):\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_svm_0(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_0(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_rf_0(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_0(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_knn_0(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_0(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_dt_0(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_0(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_0, label=ClassLabels.BASOPHIL)\n",
    "def LF_lr_0(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.BASOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_1(x,**kwargs):\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_svm_1(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_1(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_rf_1(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_1(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_knn_1(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_1(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_dt_1(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_1(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_1, label=ClassLabels.EOSINOPHIL)\n",
    "def LF_lr_1(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.EOSINOPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_2(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'2_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_2, label=ClassLabels.ERYTHROBLAST)\n",
    "def LF_svm_2(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'2_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.ERYTHROBLAST\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_2(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'2_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_2, label=ClassLabels.ERYTHROBLAST)\n",
    "def LF_rf_2(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'2_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.ERYTHROBLAST\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_2(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'2_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_2, label=ClassLabels.ERYTHROBLAST)\n",
    "def LF_knn_2(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'2_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.ERYTHROBLAST\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_2(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'2_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_2, label=ClassLabels.ERYTHROBLAST)\n",
    "def LF_dt_2(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'2_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.ERYTHROBLAST\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_2(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'2_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_2, label=ClassLabels.ERYTHROBLAST)\n",
    "def LF_lr_2(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'2_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.ERYTHROBLAST\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_3(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'3_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_3, label=ClassLabels.IMG)\n",
    "def LF_svm_3(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'3_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.IMG\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_3(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'3_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_3, label=ClassLabels.IMG)\n",
    "def LF_rf_3(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'3_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.IMG\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_3(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'3_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_3, label=ClassLabels.IMG)\n",
    "def LF_knn_3(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'3_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.IMG\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_3(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'3_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_3, label=ClassLabels.IMG)\n",
    "def LF_dt_3(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'3_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.IMG\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_3(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'3_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_3, label=ClassLabels.IMG)\n",
    "def LF_lr_3(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'3_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.IMG\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_4(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'4_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_4, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_svm_4(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'4_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_4(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'4_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_4, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_rf_4(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'4_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_4(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'4_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_4, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_knn_4(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'4_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_4(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'4_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_4, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_dt_4(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'4_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_4(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'4_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_4, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_lr_4(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'4_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_5(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'5_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_5, label=ClassLabels.MONOCYTE)\n",
    "def LF_svm_5(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'5_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.MONOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_5(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'5_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_5, label=ClassLabels.MONOCYTE)\n",
    "def LF_rf_5(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'5_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.MONOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_5(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'5_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_5, label=ClassLabels.MONOCYTE)\n",
    "def LF_knn_5(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'5_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.MONOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_5(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'5_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_5, label=ClassLabels.MONOCYTE)\n",
    "def LF_dt_5(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'5_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.MONOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_5(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'5_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_5, label=ClassLabels.MONOCYTE)\n",
    "def LF_lr_5(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'5_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.MONOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_6(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'6_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_6, label=ClassLabels.NEUTROPHIL)\n",
    "def LF_svm_6(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'6_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NEUTROPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_6(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'6_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_6, label=ClassLabels.NEUTROPHIL)\n",
    "def LF_rf_6(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'6_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NEUTROPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_6(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'6_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_6, label=ClassLabels.NEUTROPHIL)\n",
    "def LF_knn_6(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'6_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NEUTROPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_6(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'6_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_6, label=ClassLabels.NEUTROPHIL)\n",
    "def LF_dt_6(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'6_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NEUTROPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_6(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'6_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_6, label=ClassLabels.NEUTROPHIL)\n",
    "def LF_lr_6(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'6_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NEUTROPHIL\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_7(x,**kwargs):\n",
    "    x = np.array(x).flatten()   \n",
    "    svm = pickle.load(open(path+'7_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    return float(confidence_scores[0][1])  \n",
    "\n",
    "@labeling_function(cont_scorer=svm_7, label=ClassLabels.PLATELET)\n",
    "def LF_svm_7(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'7_svm.pkl','rb'))\n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_7(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'7_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_7, label=ClassLabels.PLATELET)\n",
    "def LF_rf_7(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'7_rf.pkl','rb'))\n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_7(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'7_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_7, label=ClassLabels.PLATELET)\n",
    "def LF_knn_7(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'7_knn.pkl','rb'))\n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_7(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'7_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_7, label=ClassLabels.PLATELET)\n",
    "def LF_dt_7(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'7_dtc.pkl','rb'))\n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_7(x,**kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'7_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_7, label=ClassLabels.PLATELET)\n",
    "def LF_lr_7(x, **kwargs):\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'7_lr.pkl','rb'))\n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.PLATELET\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating LFs & Labelling dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFSet\n",
    "Placeholder for declared LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import LFSet\n",
    "\n",
    "LFS = [\n",
    "    LF_svm_0,\n",
    "    LF_rf_0,\n",
    "    LF_knn_0,\n",
    "    LF_dt_0,\n",
    "    LF_lr_0,\n",
    "    LF_svm_1,\n",
    "    LF_rf_1,\n",
    "    LF_knn_1,\n",
    "    LF_dt_1,\n",
    "    LF_lr_1,\n",
    "    LF_svm_2,\n",
    "    LF_rf_2,\n",
    "    LF_knn_2,\n",
    "    LF_dt_2,\n",
    "    LF_lr_2,\n",
    "    LF_svm_3,\n",
    "    LF_rf_3,\n",
    "    LF_knn_3,\n",
    "    LF_dt_3,\n",
    "    LF_lr_3,\n",
    "    LF_svm_4,\n",
    "    LF_rf_4,\n",
    "    LF_knn_4,\n",
    "    LF_dt_4,\n",
    "    LF_lr_4,\n",
    "    LF_svm_5,\n",
    "    LF_rf_5,\n",
    "    LF_knn_5,\n",
    "    LF_dt_5,\n",
    "    LF_lr_5,\n",
    "    LF_svm_6,\n",
    "    LF_rf_6,\n",
    "    LF_knn_6,\n",
    "    LF_dt_6,\n",
    "    LF_lr_6,\n",
    "    LF_svm_7,\n",
    "    LF_rf_7,\n",
    "    LF_knn_7,\n",
    "    LF_dt_7,\n",
    "    LF_lr_7,\n",
    "]\n",
    "\n",
    "\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "classes,label_frac,data_path,save_path = get_variables2()\n",
    "dataset,x,y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)\n",
    "yOracle = copy.deepcopy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map (curr, cls):\n",
    "    if curr==cls:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnScore(x, y,i):\n",
    "    x_train = np.array(x).reshape(-1, 28, 28, 3)\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    y_train = [int(i) for i in y]\n",
    "    y_train = np_utils.to_categorical(y_train, len(classes))\n",
    "\n",
    "    # Load Validation Data\n",
    "    # 5% of Val Set to Test CNN after every iteration\n",
    "    x_val, dummy1, y_val, dummy2 = train_test_split(dataset[\"val_images\"], dataset[\"val_labels\"], train_size=0.2)\n",
    "    x_val = np.array(x_val).reshape(-1, 28, 28, 3)\n",
    "    x_val = x_val.astype(\"float32\") / 255\n",
    "    y_val = [int(i) for i in y_val] \n",
    "    \n",
    "    xv = []\n",
    "    yv = []\n",
    "    class_limit = int(0.05*len(dataset[\"val_labels\"])/len(classes))\n",
    "    for j in range(len(classes)):\n",
    "        for i in range(len(y_val)):\n",
    "            if  yv.count(j) < class_limit and y_val[i] == j:\n",
    "                xv.append(x_val[i])\n",
    "                yv.append(y_val[i])\n",
    "\n",
    "    # print('*'*80)\n",
    "    # print([yv.count(i) for i in range(len(classes))])\n",
    "\n",
    "    xv = np.array(xv)\n",
    "    yv = np.array(yv)\n",
    "    yv = np_utils.to_categorical(yv, num_classes=len(classes))\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 25\n",
    "    model = create_cnn(num_classes = len(classes))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose = 0)\n",
    "    return model.evaluate(xv, yv, verbose = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cage_loop(LFS, max_iters=10, threshold=10**-5, img_per_class = 150):\n",
    "    # Paths\n",
    "    log_path_cage = './cage_loop2/log.txt' \n",
    "    params_path = None\n",
    "    path_json = \"./cage_loop2/labels.json\"\n",
    "    U_path_pkl = \"./cage_loop2/unlabelled.pkl\"\n",
    "    L_path_pkl = \"./cage_loop2/labelled.pkl\"\n",
    "\n",
    "    # Loading Data\n",
    "    classes,label_frac,data_path,save_path = get_variables2()\n",
    "    dataset,x,y = custom_dataset(classes=classes, path=data_path, fraction=label_frac)\n",
    "    xu = np.array(dataset['rem_images'])\n",
    "    yu = np.array(dataset['rem_labels'])\n",
    "    yOracle = copy.deepcopy(y)\n",
    "    \n",
    "    print(\"Classes used in expt:\",classes)\n",
    "\n",
    "    # Creating rules\n",
    "    n_lfs = len(LFS)\n",
    "    rules = LFSet(\"BM_LF\")\n",
    "    rules.add_lf_list(LFS)\n",
    "    \n",
    "    confidence_list = []\n",
    "    val_scores = []\n",
    "    oracle_val_scores = []\n",
    "    classwise_accuracies = []\n",
    "    pl_accuracies = []\n",
    "    for i in range(max_iters):\n",
    "        # Train Models in LFs\n",
    "        train_all_LF(x,y,len(classes),save_path,label_frac)\n",
    "\n",
    "        # Unlabelled\n",
    "        u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
    "                                    data=xu,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Lu,Su = u_noisy_labels.get_labels()\n",
    "        # if i!=0:\n",
    "        u_noisy_labels.generate_pickle(U_path_pkl)\n",
    "        u_noisy_labels.generate_json(path_json)\n",
    "\n",
    "        # Labelled\n",
    "        # l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
    "        #                             data=x,\n",
    "        #                             gold_labels=y,\n",
    "        #                             rules=rules,\n",
    "        #                             labels_enum=ClassLabels,\n",
    "        #                             num_classes=len(classes))\n",
    "        # # Ll,Sl = l_noisy_labels.get_labels()\n",
    "        # l_noisy_labels.generate_pickle(L_path_pkl)\n",
    "        # l_noisy_labels.generate_json(path_json)\n",
    "\n",
    "\n",
    "        # Cage\n",
    "        cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
    "        if params_path is not None: \n",
    "            cage.load_params(load_path = params_path)\n",
    "        else:\n",
    "            params_path = './cage_loop2/params.pkl' \n",
    "        \n",
    "        probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_log = log_path_cage, qt = 0.9, qc = 0.85, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
    "        labels = np.argmax(probs, 1)\n",
    "\n",
    "        print(\"=\"*135)\n",
    "        print(\"Iteration\",i)\n",
    "        values, frequency = np.unique(yu, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Lake Class {values}: {frequency}\")\n",
    "\n",
    "        values, frequency = np.unique(y, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Labelled Set {values}: {frequency}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Shape of Labeled Data:\",x.shape)\n",
    "        print(\"Shape of Unlabeled Data:\",xu.shape)\n",
    "        print(\"Accuracy on unlabelled images:\",accuracy_score(labels,yu)*100)\n",
    "        \n",
    "        \n",
    "        cage.save_params(save_path = params_path)\n",
    "\n",
    "        confidence = np.array([np.max(i) for i in probs])\n",
    "        confidence_list.append(confidence)\n",
    "        print(i,probs.shape)\n",
    "\n",
    "        # Getting indices of probabilities in decreasing order\n",
    "        idx = np.argsort(confidence)\n",
    "        idx = idx[::-1] \n",
    "\n",
    "        # Number of images per class (5%)\n",
    "        # img_per_class = int(0.05*len(confidence)/len(classes))\n",
    "\n",
    "        # Number of images per class (50)\n",
    "        \n",
    "        \n",
    "        print(\"Num img per class =\",img_per_class)\n",
    "\n",
    "        pop_list = [] #list of indices of images to be added\n",
    "        label_count = []\n",
    "        threshcount = 0\n",
    "        unl = []\n",
    "        for j in idx:\n",
    "            if confidence[j]>threshold:\n",
    "                threshcount+=1\n",
    "                unl.append(labels[j])\n",
    "\n",
    "            if confidence[j]>threshold and label_count.count(labels[j])<img_per_class:\n",
    "                pop_list.append(j)\n",
    "                label_count.append(labels[j])\n",
    "        \n",
    "        print(\"Number of images above threshold:\",threshcount)\n",
    "        print(\"Classes of images above threshold:\",set(unl))\n",
    "        print(\"Number of images getting transferred:\", len(pop_list))\n",
    "        print('Accuracy of Pseudo-labelled img added to dataset:', accuracy_score(labels[pop_list],yu[pop_list])*100)\n",
    "        pl_accuracies.append(accuracy_score(labels[pop_list],yu[pop_list])*100)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cmidx = [[(map(yu[j],i), map(labels[j],i)) for j in range(len(labels))] for i in range(len(classes))]\n",
    "        cacc = []\n",
    "        fig, ax = plt.subplots(math.ceil(len(classes)/2),2, figsize=(15, 20))\n",
    "        pltnum = 0\n",
    "        for cmid in cmidx:\n",
    "            cacc.append(accuracy_score([z[0] for z in cmid], [z[1] for z in cmid])*100)\n",
    "            ax[pltnum//2,pltnum%2].set_title(f\"Class {pltnum}\")\n",
    "            confusion_matrix = metrics.confusion_matrix([z[0] for z in cmid], [z[1] for z in cmid])\n",
    "            cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "            cm_display.plot(ax=ax[pltnum//2,pltnum%2])\n",
    "            pltnum += 1\n",
    "        classwise_accuracies.append(cacc)\n",
    "        fig.suptitle(f\"Iteration {i}\")\n",
    "        plt.show()\n",
    "        plt.savefig(f\"all_cm_iteration_{i}.jpg\")\n",
    "\n",
    "        if len(pop_list)<50:\n",
    "            break\n",
    "        \n",
    "        x = np.append(x,xu[pop_list], axis=0)\n",
    "        y = np.append(y,labels[pop_list], axis=0)\n",
    "        yOracle = np.append(yOracle,yu[pop_list], axis=0)\n",
    "        xu = np.delete(xu,pop_list, axis=0)\n",
    "        yu = np.delete(yu,pop_list, axis=0)\n",
    "\n",
    "        # Deleting variables\n",
    "        del u_noisy_labels\n",
    "        del cage\n",
    "\n",
    "        classes,label_frac,data_path,save_path = get_variables2()\n",
    "\n",
    "        val_scores.append(cnnScore(x, y,i)[1]*100)\n",
    "        oracle_val_scores.append(cnnScore(x,yOracle,i)[1]*100)\n",
    "        print(f\"CNN Val accuracy trained on Lake Set for iteration {i}: \", val_scores[i])\n",
    "        print(f\"CNN Val accuracy trained on Oracle for iteration {i}: \", oracle_val_scores[i])\n",
    "\n",
    "        # for j in range(len(classes)):\n",
    "        #     if label_count.count(j)<75:\n",
    "        #         print(\"*\"*60+\"Predicted Break\"+\"*\"*60)\n",
    "        #         break\n",
    "\n",
    "        \n",
    "        print(\"=\"*135)\n",
    "        # if i>0 and val_scores[i]<val_scores[i-1]:\n",
    "        #     break\n",
    "\n",
    "\n",
    "    return x,y,xu,yu,confidence_list, val_scores, oracle_val_scores, classwise_accuracies, pl_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes used in expt: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n",
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 3710/11847 [13:58<30:48,  4.40it/s] "
     ]
    }
   ],
   "source": [
    "#  img_per_class: num images added per loop per class\n",
    "x,y,xu,yu,confidence_list, val_scores, oracle_val_scores, classwise_accuracies, pl_accuracies = cage_loop(LFS, max_iters=1, threshold=10**-5,  img_per_class = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43.75,\n",
       " 57.499998807907104,\n",
       " 68.75,\n",
       " 80.0000011920929,\n",
       " 82.4999988079071,\n",
       " 87.5,\n",
       " 85.00000238418579,\n",
       " 88.7499988079071,\n",
       " 92.5000011920929,\n",
       " 91.25000238418579]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_scores\n",
    "oracle_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([val_scores,oracle_val_scores,pl_accuracies], columns=[f'Iteration {i}' for i in range(len(val_scores))], index=['Our Results','Oracle/Skyline',\"Pseudo Labelled\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration 0</th>\n",
       "      <th>Iteration 1</th>\n",
       "      <th>Iteration 2</th>\n",
       "      <th>Iteration 3</th>\n",
       "      <th>Iteration 4</th>\n",
       "      <th>Iteration 5</th>\n",
       "      <th>Iteration 6</th>\n",
       "      <th>Iteration 7</th>\n",
       "      <th>Iteration 8</th>\n",
       "      <th>Iteration 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Our Results</th>\n",
       "      <td>44.999999</td>\n",
       "      <td>58.749998</td>\n",
       "      <td>62.50</td>\n",
       "      <td>63.749999</td>\n",
       "      <td>61.250001</td>\n",
       "      <td>64.999998</td>\n",
       "      <td>67.500001</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>66.250002</td>\n",
       "      <td>66.250002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle/Skyline</th>\n",
       "      <td>43.750000</td>\n",
       "      <td>57.499999</td>\n",
       "      <td>68.75</td>\n",
       "      <td>80.000001</td>\n",
       "      <td>82.499999</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>85.000002</td>\n",
       "      <td>88.749999</td>\n",
       "      <td>92.500001</td>\n",
       "      <td>91.250002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Iteration 0  Iteration 1  Iteration 2  Iteration 3  \\\n",
       "Our Results       44.999999    58.749998        62.50    63.749999   \n",
       "Oracle/Skyline    43.750000    57.499999        68.75    80.000001   \n",
       "\n",
       "                Iteration 4  Iteration 5  Iteration 6  Iteration 7  \\\n",
       "Our Results       61.250001    64.999998    67.500001    62.500000   \n",
       "Oracle/Skyline    82.499999    87.500000    85.000002    88.749999   \n",
       "\n",
       "                Iteration 8  Iteration 9  \n",
       "Our Results       66.250002    66.250002  \n",
       "Oracle/Skyline    92.500001    91.250002  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemblelf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65b9741ba6eaae6d85890be96456298c2d24fb14f0ef87b0a39bd8b2cf5b4454"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
