{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.438978906Z",
     "start_time": "2023-05-19T17:17:14.392834211Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from resnet18 import ResNet, BasicBlock\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.440927666Z",
     "start_time": "2023-05-19T17:17:14.439540844Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_resnet18_model(model_path, num_classes=2, num_channels=3):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model_path: Path to ResNet18 model\n",
    "    :param num_channels: Number of channels in image, also depends on trained model\n",
    "    :return: Instance of the model (torchvision.models.resnet18() in eval mode)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an instance of the ResNet18 model\n",
    "    model = ResNet(img_channels=num_channels, num_layers=18, block=BasicBlock, num_classes=num_classes).to(device)\n",
    "\n",
    "    # Load the saved state dictionary into the model\n",
    "    # map_location = device makes code compatible for CPU and GPU\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_image_with_transform(input_img, num_channels=3):\n",
    "    input_img = input_img.copy()\n",
    "\n",
    "    # input_img.resize((224, 224, 3))\n",
    "    # input_img = input_img * 255 / np.max(input_img)\n",
    "    # input_img = input_img.astype(np.uint8)\n",
    "\n",
    "    input_img = Image.fromarray(input_img)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        # transforms.Grayscale(num_output_channels=1)\n",
    "    ])\n",
    "\n",
    "    input_img = transform(input_img)\n",
    "\n",
    "    n = 224\n",
    "\n",
    "    input_img = torch.tensor(input_img.clone().detach().requires_grad_(True), dtype=torch.float)\n",
    "    input_img = input_img.view(1, num_channels, n, n).to(device)\n",
    "\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.477247443Z",
     "start_time": "2023-05-19T17:17:14.440028298Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/home/raja/Desktop/MICCAI/code/18_resnet/models/best.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.570764306Z",
     "start_time": "2023-05-19T17:17:14.478950230Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.571079018Z",
     "start_time": "2023-05-19T17:17:14.565574598Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8043/499375677.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_img = torch.tensor(input_img.clone().detach().requires_grad_(True), dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.7015e-05, 9.9994e-01]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = plt.imread('data/NONLYMPHOCYTES/img_2_cropped_30.jpg')\n",
    "transformed_img =  load_image_with_transform(img, num_channels=3)\n",
    "\n",
    "outputs = model(transformed_img)\n",
    "outputs = F.softmax(outputs, dim=1)\n",
    "predicted_class = torch.argmax(outputs, dim=1)\n",
    "confidence_scores = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "_, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "#classes = ['Lymphocyte', 'Non-Lymphocyte']\n",
    "classes = [0,1]\n",
    "\n",
    "class_prediction = classes[preds.tolist()[0]]\n",
    "\n",
    "class_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:40.521082007Z",
     "start_time": "2023-05-19T17:17:40.236790905Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8043/499375677.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_img = torch.tensor(input_img.clone().detach().requires_grad_(True), dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "class_predictions = []\n",
    "\n",
    "for img_name in os.listdir('/home/raja/Desktop/segment-anything/test-data-output/test-output-v2'):\n",
    "    img = plt.imread(os.path.join('/home/raja/Desktop/segment-anything/test-data-output', 'test-output-v2', img_name))\n",
    "    transformed_img = load_image_with_transform(img, num_channels=3)\n",
    "\n",
    "    outputs = model(transformed_img)\n",
    "    outputs = F.softmax(outputs, dim=1)\n",
    "\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "    classes = [0, 1]\n",
    "    class_prediction = classes[preds.tolist()[0]]\n",
    "\n",
    "    class_predictions.append(class_prediction)\n",
    "\n",
    "#print(class_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.858824389Z",
     "start_time": "2023-05-19T17:17:14.857501145Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Combine image names and predicted labels\n",
    "data = zip(os.listdir('/home/raja/Desktop/segment-anything/test-data-output/test-output-v2'), class_predictions)\n",
    "\n",
    "# Write to CSV file\n",
    "with open('/home/raja/Desktop/MICCAI/code/18_resnet/predictions-resnet.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Image Name', 'Label'])\n",
    "    for row in data:\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# Define input and output file names\n",
    "input_file = '/home/raja/Desktop/MICCAI/code/18_resnet/predictions-resnet.csv'\n",
    "output_file = '/home/raja/Desktop/MICCAI/code/18_resnet/output-resnet.csv'\n",
    "\n",
    "# Define dictionary to store counts for each image\n",
    "image_counts = {}\n",
    "\n",
    "# Define regular expression to extract image number from filename\n",
    "img_regex = re.compile(r'img_(\\d+)_cropped_\\d+.jpg')\n",
    "\n",
    "# Read input file and count labels for each image\n",
    "with open(input_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header row\n",
    "    for row in reader:\n",
    "        image_name, label = row\n",
    "        img_match = img_regex.match(image_name)\n",
    "        if img_match:\n",
    "            image_number = int(img_match.group(1))\n",
    "            if image_number in image_counts:\n",
    "                if label == '0':\n",
    "                    image_counts[image_number][0] += 1\n",
    "                else:\n",
    "                    image_counts[image_number][1] += 1\n",
    "            else:\n",
    "                if label == '0':\n",
    "                    image_counts[image_number] = {0: 1, 1: 0}\n",
    "                else:\n",
    "                    image_counts[image_number] = {0: 0, 1: 1}\n",
    "\n",
    "# Write output file with counts for each image\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Image', 'Predicted-Lymphocyte'])\n",
    "    for image_number, counts in sorted(image_counts.items()):\n",
    "        writer.writerow(['img_{}'.format(image_number), counts[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the csv file into a pandas DataFrame\n",
    "df = pd.read_csv('/home/raja/Desktop/MICCAI/code/18_resnet/output-resnet.csv')\n",
    "\n",
    "# create a new DataFrame with the full range of image numbers\n",
    "img_range = range(20000)\n",
    "new_df = pd.DataFrame({'Image': ['img_' + str(i) for i in img_range], 'Predicted-Lymphocyte': 0})\n",
    "\n",
    "# merge the new DataFrame with the original DataFrame using a left join\n",
    "merged_df = pd.merge(new_df, df, on='Image', how='left')\n",
    "\n",
    "\n",
    "# write the merged DataFrame to a new csv file\n",
    "merged_df.to_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file-itr2.csv', index=False)\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file-itr2.csv')\n",
    "\n",
    "# Fill the 'predicted' column with 0 for NA values\n",
    "df['Predicted-Lymphocyte_y'].fillna(0, inplace=True)\n",
    "\n",
    "# Save the modified DataFrame back to Excel\n",
    "df.to_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file-itr2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\n\\n# read the input CSV file into a pandas dataframe\\ndf = pd.read_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file.csv')\\n\\n# define the function to assign class labels based on ground truth values\\ndef assign_class(gt):\\n    if gt == 0:\\n        return '0 (None)'\\n    elif 1 <= gt <= 5:\\n        return '1-5'\\n    elif 6 <= gt <= 10:\\n        return '6-10'\\n    elif 11 <= gt <= 20:\\n        return '11-20'\\n    elif 21 <= gt <= 50:\\n        return '21-50'\\n    elif 51 <= gt <= 200:\\n        return '51-200'\\n    else:\\n        return '>200'\\n\\n# assign class labels to ground truth values\\ndf['Ground-truth Class'] = df['Ground-truth'].apply(assign_class)\\n\\n# assign class labels to predicted values based on the constraints\\ndf['Predicted Class'] = df.apply(lambda row: assign_class(row['Predicted-Lymphocyte_y']), axis=1)\\n\\n# calculate the confusion matrix\\nconfusion_matrix = pd.crosstab(df['Ground-truth Class'], df['Predicted Class'])\\n\\n# define the desired order of the classes\\ndesired_order = ['0 (None)', '1-5', '6-10', '11-20', '21-50']\\n\\n# reindex the confusion matrix to match the desired order\\nconfusion_matrix = confusion_matrix.reindex(index=desired_order, columns=desired_order, fill_value=0)\\n\\n# print the confusion matrix\\nprint(confusion_matrix)\\n\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# read the input CSV file into a pandas dataframe\n",
    "df = pd.read_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file.csv')\n",
    "\n",
    "# define the function to assign class labels based on ground truth values\n",
    "def assign_class(gt):\n",
    "    if gt == 0:\n",
    "        return '0 (None)'\n",
    "    elif 1 <= gt <= 5:\n",
    "        return '1-5'\n",
    "    elif 6 <= gt <= 10:\n",
    "        return '6-10'\n",
    "    elif 11 <= gt <= 20:\n",
    "        return '11-20'\n",
    "    elif 21 <= gt <= 50:\n",
    "        return '21-50'\n",
    "    elif 51 <= gt <= 200:\n",
    "        return '51-200'\n",
    "    else:\n",
    "        return '>200'\n",
    "\n",
    "# assign class labels to ground truth values\n",
    "df['Ground-truth Class'] = df['Ground-truth'].apply(assign_class)\n",
    "\n",
    "# assign class labels to predicted values based on the constraints\n",
    "df['Predicted Class'] = df.apply(lambda row: assign_class(row['Predicted-Lymphocyte_y']), axis=1)\n",
    "\n",
    "# calculate the confusion matrix\n",
    "confusion_matrix = pd.crosstab(df['Ground-truth Class'], df['Predicted Class'])\n",
    "\n",
    "# define the desired order of the classes\n",
    "desired_order = ['0 (None)', '1-5', '6-10', '11-20', '21-50']\n",
    "\n",
    "# reindex the confusion matrix to match the desired order\n",
    "confusion_matrix = confusion_matrix.reindex(index=desired_order, columns=desired_order, fill_value=0)\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f5b4396ae54b339dce7091723dfd2c38ad833227f8e97d2a6323021886247d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
