{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms, models \n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import custom_dataset\n",
    "from generate_LF import get_variables\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "xu = np.array(dataset['rem_images'])\n",
    "yu = np.array(dataset['rem_labels'])\n",
    "\n",
    "path=\"C:/Users/akshi/Desktop/DDP/MICCAI/data/\"\n",
    "data = np.load(path+\"bloodmnist.npz\")\n",
    "\n",
    "train_images = data[\"train_images\"]\n",
    "train_labels = data[\"train_images\"]\n",
    "val_images = data[\"val_images\"]\n",
    "val_labels = data[\"val_images\"]\n",
    "test_images = data[\"test_images\"]\n",
    "test_labels = data[\"test_images\"]\n",
    "\n",
    "\n",
    "class MedMNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = torch.from_numpy(images).float()\n",
    "        self.labels = torch.from_numpy(labels).int()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MedMNISTDataset(train_images, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(3,6,3,1)\n",
    "        self.conv2=nn.Conv2d(6,16,3,1)\n",
    "        self.fc1=nn.Linear(16*54*54,120) \n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,20)\n",
    "        self.fc4=nn.Linear(20,len(class_names))\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X=F.relu(self.conv1(X))\n",
    "        X=F.max_pool2d(X,2,2)\n",
    "        X=F.relu(self.conv2(X))\n",
    "        X=F.max_pool2d(X,2,2)\n",
    "        X=X.view(-1,16*54*54)\n",
    "        X=F.relu(self.fc1(X))\n",
    "        X=F.relu(self.fc2(X))\n",
    "        X=F.relu(self.fc3(X))\n",
    "        X=self.fc4(X)\n",
    "        return F.log_softmax(X,dim=1)\n",
    "\n",
    "model=ConvolutionalNetwork()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform=transforms.Compose([\n",
    "        transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
    "        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
    "        transforms.Resize(224),             # resize shortest side to 224 pixels\n",
    "        transforms.CenterCrop(224),         # crop longest side to 224 pixels at center\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "    # training code here\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18cf254994e8ef31ff253b06bffdcac9cd04b64e5eca6cffd207f4db2ac21b0f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('ensemblelf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
