{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.438978906Z",
     "start_time": "2023-05-19T17:17:14.392834211Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from resnet18 import ResNet, BasicBlock\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.440927666Z",
     "start_time": "2023-05-19T17:17:14.439540844Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_resnet18_model(model_path, num_classes=2, num_channels=3):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model_path: Path to ResNet18 model\n",
    "    :param num_channels: Number of channels in image, also depends on trained model\n",
    "    :return: Instance of the model (torchvision.models.resnet18() in eval mode)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an instance of the ResNet18 model\n",
    "    model = ResNet(img_channels=num_channels, num_layers=18, block=BasicBlock, num_classes=num_classes).to(device)\n",
    "\n",
    "    # Load the saved state dictionary into the model\n",
    "    # map_location = device makes code compatible for CPU and GPU\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_image_with_transform(input_img, num_channels=3):\n",
    "    input_img = input_img.copy()\n",
    "\n",
    "    # input_img.resize((224, 224, 3))\n",
    "    # input_img = input_img * 255 / np.max(input_img)\n",
    "    # input_img = input_img.astype(np.uint8)\n",
    "\n",
    "    input_img = Image.fromarray(input_img)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        # transforms.Grayscale(num_output_channels=1)\n",
    "    ])\n",
    "\n",
    "    input_img = transform(input_img)\n",
    "\n",
    "    n = 224\n",
    "\n",
    "    input_img = torch.tensor(input_img.clone().detach().requires_grad_(True), dtype=torch.float)\n",
    "    input_img = input_img.view(1, num_channels, n, n).to(device)\n",
    "\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.477247443Z",
     "start_time": "2023-05-19T17:17:14.440028298Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/home/raja/Desktop/MICCAI/code/18_resnet/models/best.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.570764306Z",
     "start_time": "2023-05-19T17:17:14.478950230Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.571079018Z",
     "start_time": "2023-05-19T17:17:14.565574598Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimg = plt.imread('data/NONLYMPHOCYTES/img_2_cropped_30.jpg')\\ntransformed_img =  load_image_with_transform(img, num_channels=3)\\n\\noutputs = model(transformed_img)\\noutputs = F.softmax(outputs, dim=1)\\npredicted_class = torch.argmax(outputs, dim=1)\\nconfidence_scores = torch.nn.functional.softmax(outputs, dim=1)\\n\\nprint(outputs)\\n\\n_, preds = torch.max(outputs.data, 1)\\n\\n#classes = ['Lymphocyte', 'Non-Lymphocyte']\\nclasses = [0,1]\\n\\nclass_prediction = classes[preds.tolist()[0]]\\n\\nclass_prediction\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "img = plt.imread('data/NONLYMPHOCYTES/img_2_cropped_30.jpg')\n",
    "transformed_img =  load_image_with_transform(img, num_channels=3)\n",
    "\n",
    "outputs = model(transformed_img)\n",
    "outputs = F.softmax(outputs, dim=1)\n",
    "predicted_class = torch.argmax(outputs, dim=1)\n",
    "confidence_scores = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "_, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "#classes = ['Lymphocyte', 'Non-Lymphocyte']\n",
    "classes = [0,1]\n",
    "\n",
    "class_prediction = classes[preds.tolist()[0]]\n",
    "\n",
    "class_prediction\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:40.521082007Z",
     "start_time": "2023-05-19T17:17:40.236790905Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_105286/499375677.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_img = torch.tensor(input_img.clone().detach().requires_grad_(True), dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "class_predictions = []\n",
    "\n",
    "for img_name in os.listdir('/home/raja/Desktop/MICCAI/test_folder'):\n",
    "    img = plt.imread(os.path.join('/home/raja/Desktop/MICCAI', 'test_folder', img_name))\n",
    "    transformed_img = load_image_with_transform(img, num_channels=3)\n",
    "\n",
    "    outputs = model(transformed_img)\n",
    "    outputs = F.softmax(outputs, dim=1)\n",
    "\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "    classes = [0, 1]\n",
    "    class_prediction = classes[preds.tolist()[0]]\n",
    "\n",
    "    class_predictions.append(class_prediction)\n",
    "\n",
    "#print(class_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:17:14.858824389Z",
     "start_time": "2023-05-19T17:17:14.857501145Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Combine image names and predicted labels\n",
    "data = zip(os.listdir('/home/raja/Desktop/MICCAI/test_folder'), class_predictions)\n",
    "\n",
    "# Write to CSV file\n",
    "with open('/home/raja/Desktop/MICCAI/code/18_resnet/predictions-resnet.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Image Name', 'Label'])\n",
    "    for row in data:\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'image_counts.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import re\n",
    "# Initialize a dictionary to store the counts\n",
    "counts = defaultdict(int)\n",
    "\n",
    "# Read the CSV file and populate the counts dictionary\n",
    "with open('/home/raja/Desktop/MICCAI/code/18_resnet/predictions-resnet.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip the header row if present\n",
    "\n",
    "    # Iterate over the rows in the CSV\n",
    "    for row in reader:\n",
    "        image_name = row[0]\n",
    "        label = int(row[1])\n",
    "\n",
    "        # Extract the image number\n",
    "        match = re.search(r'img_(\\d+)', image_name)\n",
    "        if match:\n",
    "            image_number = int(match.group(1))\n",
    "\n",
    "            # Check if the label is 0\n",
    "            if label == 0:\n",
    "                counts[image_number] += 1\n",
    "\n",
    "# Add missing image numbers with count 0\n",
    "for image_number in range(18000, 20000):\n",
    "    if image_number not in counts:\n",
    "        counts[image_number] = 0\n",
    "\n",
    "# Write the counts to a new CSV file\n",
    "with open('/home/raja/Desktop/MICCAI/code/18_resnet/image_counts.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['img_number', 'count'])  # Write header row\n",
    "\n",
    "    # Write the image numbers and counts\n",
    "    for image_number, count in sorted(counts.items()):\n",
    "        writer.writerow([image_number, count])\n",
    "\n",
    "print(\"CSV file 'image_counts.csv' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\n\\n# read the csv file into a pandas DataFrame\\ndf = pd.read_csv('/home/raja/Desktop/MICCAI/code/18_resnet/output-resnet.csv')\\n\\n# create a new DataFrame with the full range of image numbers\\nimg_range = range(20000)\\nnew_df = pd.DataFrame({'Image': ['img_' + str(i) for i in img_range], 'Predicted-Lymphocyte': 0})\\n\\n# merge the new DataFrame with the original DataFrame using a left join\\nmerged_df = pd.merge(new_df, df, on='Image', how='left')\\n\\n\\n# write the merged DataFrame to a new csv file\\nmerged_df.to_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file-itr2.csv', index=False)\\n\\n# Load the Excel file\\ndf = pd.read_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file-itr2.csv')\\n\\n# Fill the 'predicted' column with 0 for NA values\\ndf['Predicted-Lymphocyte_y'].fillna(0, inplace=True)\\n\\n# Save the modified DataFrame back to Excel\\ndf.to_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file-itr2.csv', index=False)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# read the csv file into a pandas DataFrame\n",
    "df = pd.read_csv('/home/raja/Desktop/MICCAI/code/18_resnet/output-resnet.csv')\n",
    "\n",
    "# create a new DataFrame with the full range of image numbers\n",
    "img_range = range(20000)\n",
    "new_df = pd.DataFrame({'Image': ['img_' + str(i) for i in img_range], 'Predicted-Lymphocyte': 0})\n",
    "\n",
    "# merge the new DataFrame with the original DataFrame using a left join\n",
    "merged_df = pd.merge(new_df, df, on='Image', how='left')\n",
    "\n",
    "\n",
    "# write the merged DataFrame to a new csv file\n",
    "merged_df.to_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file-itr2.csv', index=False)\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file-itr2.csv')\n",
    "\n",
    "# Fill the 'predicted' column with 0 for NA values\n",
    "df['Predicted-Lymphocyte_y'].fillna(0, inplace=True)\n",
    "\n",
    "# Save the modified DataFrame back to Excel\n",
    "df.to_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file-itr2.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\n\\n# read the input CSV file into a pandas dataframe\\ndf = pd.read_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file.csv')\\n\\n# define the function to assign class labels based on ground truth values\\ndef assign_class(gt):\\n    if gt == 0:\\n        return '0 (None)'\\n    elif 1 <= gt <= 5:\\n        return '1-5'\\n    elif 6 <= gt <= 10:\\n        return '6-10'\\n    elif 11 <= gt <= 20:\\n        return '11-20'\\n    elif 21 <= gt <= 50:\\n        return '21-50'\\n    elif 51 <= gt <= 200:\\n        return '51-200'\\n    else:\\n        return '>200'\\n\\n# assign class labels to ground truth values\\ndf['Ground-truth Class'] = df['Ground-truth'].apply(assign_class)\\n\\n# assign class labels to predicted values based on the constraints\\ndf['Predicted Class'] = df.apply(lambda row: assign_class(row['Predicted-Lymphocyte_y']), axis=1)\\n\\n# calculate the confusion matrix\\nconfusion_matrix = pd.crosstab(df['Ground-truth Class'], df['Predicted Class'])\\n\\n# define the desired order of the classes\\ndesired_order = ['0 (None)', '1-5', '6-10', '11-20', '21-50']\\n\\n# reindex the confusion matrix to match the desired order\\nconfusion_matrix = confusion_matrix.reindex(index=desired_order, columns=desired_order, fill_value=0)\\n\\n# print the confusion matrix\\nprint(confusion_matrix)\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# read the input CSV file into a pandas dataframe\n",
    "df = pd.read_csv('/home/raja/Desktop/MICCAI/code/18_resnet/new_file.csv')\n",
    "\n",
    "# define the function to assign class labels based on ground truth values\n",
    "def assign_class(gt):\n",
    "    if gt == 0:\n",
    "        return '0 (None)'\n",
    "    elif 1 <= gt <= 5:\n",
    "        return '1-5'\n",
    "    elif 6 <= gt <= 10:\n",
    "        return '6-10'\n",
    "    elif 11 <= gt <= 20:\n",
    "        return '11-20'\n",
    "    elif 21 <= gt <= 50:\n",
    "        return '21-50'\n",
    "    elif 51 <= gt <= 200:\n",
    "        return '51-200'\n",
    "    else:\n",
    "        return '>200'\n",
    "\n",
    "# assign class labels to ground truth values\n",
    "df['Ground-truth Class'] = df['Ground-truth'].apply(assign_class)\n",
    "\n",
    "# assign class labels to predicted values based on the constraints\n",
    "df['Predicted Class'] = df.apply(lambda row: assign_class(row['Predicted-Lymphocyte_y']), axis=1)\n",
    "\n",
    "# calculate the confusion matrix\n",
    "confusion_matrix = pd.crosstab(df['Ground-truth Class'], df['Predicted Class'])\n",
    "\n",
    "# define the desired order of the classes\n",
    "desired_order = ['0 (None)', '1-5', '6-10', '11-20', '21-50']\n",
    "\n",
    "# reindex the confusion matrix to match the desired order\n",
    "confusion_matrix = confusion_matrix.reindex(index=desired_order, columns=desired_order, fill_value=0)\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f5b4396ae54b339dce7091723dfd2c38ad833227f8e97d2a6323021886247d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
